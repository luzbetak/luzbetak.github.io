---
---
{% include menu.html title="Medallion Architecture in Delta Lake" %}
<p><hr width=1000 align=left>

<table width="1000">
    <tr>
        <td>
            <h1>Medallion Architecture in Delta Lake</h1>

            <h3>Overview of Medallion Architecture</h3>
            <ul>
                <li>The Medallion Architecture is a layered approach used in Delta Lake to optimize data quality and performance as data progresses through various stages.</li>
                <li>It divides the data into three primary layers, referred to as <font color=red>Bronze, Silver, Gold</font> tiers, each representing different levels of data quality, transformation, and availability.</li>
                <li>This architecture is designed to ensure data consistency, facilitate complex analytics, and minimize the cost of managing big data.</li>
            </ul>

            <h3>Bronze Layer: Raw Data Ingestion</h3>
            <ul>
                <li>The <font color=red>Bronze layer</font> is where raw, unprocessed data is stored directly from source systems.</li>
                <li>This data is ingested in its original form and might include duplicates, errors, or incomplete records.</li>
                <li>In this layer, Delta Lake efficiently handles large-scale data ingestion from multiple formats like JSON, CSV, Parquet, or Avro.</li>
                <li>The primary purpose of this layer is to store the raw, unfiltered data for future processing, ensuring data traceability.</li>
            </ul>

            <h3>Silver Layer: Cleaned and Refined Data</h3>
            <ul>
                <li>The <font color=red>Silver layer</font> involves refining, cleaning, and transforming the raw data into a more structured form.</li>
                <li>At this stage, data undergoes transformations such as removing duplicates, handling missing values, and applying business logic to make the data more consistent and usable.</li>
                <li>This layer is where data quality improvements are implemented, making it ready for analytics and reporting.</li>
                <li>Common transformations include joining data from multiple sources and filtering or aggregating information.</li>
            </ul>

            <h3>Gold Layer: Aggregated and Optimized Data</h3>
            <ul>
                <li>The <font color=red>Gold layer</font> represents the final stage where the data is fully transformed, aggregated, and optimized for high-performance analytics.</li>
                <li>In this layer, data is typically denormalized and pre-aggregated for specific business use cases such as reporting, machine learning models, or advanced analytics.</li>
                <li>This layer often contains data that is used for dashboards, KPIs, and decision-making, providing insights based on the refined and validated data.</li>
                <li>The focus here is on reducing query latency and improving performance for end-users by leveraging pre-processed and ready-to-use data.</li>
            </ul>

            <h3>Benefits of the Medallion Architecture</h3>
            <ul>
                <li><strong>Data Quality:</strong> As data moves from the Bronze to Gold layer, its quality improves, which helps to ensure accurate reporting and analytics.</li>
                <li><strong>Data Governance:</strong> Each layer provides a clear separation of raw, intermediate, and final datasets, aiding in governance and lineage tracking.</li>
                <li><strong>Scalability:</strong> The architecture is highly scalable, supporting a range of data sizes from terabytes to petabytes.</li>
                <li><strong>Flexibility:</strong> The architecture can accommodate various data sources and formats, while allowing different teams to work on separate layers without conflicts.</li>
            </ul>

            <h3>Medallion Architecture in Practice</h3>
            <ul>
                <li>In real-world implementations, teams may have different sets of Bronze, Silver, and Gold layers for each business domain (e.g., sales, finance, operations).</li>
                <li>Data engineers typically work on the Bronze and Silver layers, while analysts and data scientists use the Gold layer for insights and model training.</li>
                <li>By adopting this architecture, organizations can ensure that data is ingested, processed, and made available for decision-making with minimal latency.</li>
            </ul>
        </td>
    </tr>
</table>

<p><hr width=1000 align=left>
        <h1>Medallion Architecture with Partitioning</h1>
    <pre><code>
<span class="keyword">spark</span> = SparkSession.builder \
  .<span class="function">appName</span>(<span class="string">"Medallion Architecture"</span>) \
  .<span class="keyword">config</span>(<span class="string">"spark.sql.extensions"</span>, <span class="string">"io.delta.sql.DeltaSparkSessionExtension"</span>) \
  .<span class="keyword">config</span>(<span class="string">"spark.sql.catalog.spark_catalog"</span>, <span class="string">"org.apache.spark.sql.delta.catalog.DeltaCatalog"</span>) \
  .<span class="keyword">config</span>(<span class="string">"spark.executor.instances"</span>, <span class="string">"256"</span>) \
  .<span class="keyword">config</span>(<span class="string">"spark.sql.shuffle.partitions"</span>, <span class="string">"1024"</span>) \
  .<span class="function">getOrCreate</span>()

<span class="comment"># Paths for the Bronze, Silver, and Gold layers</span>
<span class="keyword">bronze_path</span> = <span class="string">"/mnt/delta/bronze"</span>
<span class="keyword">silver_path</span> = <span class="string">"/mnt/delta/silver"</span>
<span class="keyword">gold_path</span>   = <span class="string">"/mnt/delta/gold"</span>

<span class="comment"># ----------- Bronze Layer (Raw Data Ingestion) ----------------------------- #</span>
<span class="keyword">raw_data</span> = spark.<span class="function">read</span>().<span class="keyword">format</span>(<span class="string">"json"</span>).<span class="function">load</span>(<span class="string">"/mnt/raw_data/"</span>)
<span class="keyword">raw_data</span> = <span class="keyword">raw_data</span>.<span class="function">repartition</span>(1024)
<span class="keyword">raw_data</span>.<span class="function">write</span>().<span class="keyword">format</span>(<span class="string">"delta"</span>).<span class="keyword">mode</span>(<span class="string">"overwrite"</span>).<span class="function">save</span>(<span class="keyword">bronze_path</span>)


<span class="comment"># ----------- Silver Layer (Data Cleaning and Transformation) --------------- #</span>
<span class="datatype">bronze_df</span> = spark.<span class="function">read</span>().<span class="keyword">format</span>(<span class="string">"delta"</span>).<span class="function">load</span>(<span class="keyword">bronze_path</span>)

<span class="comment"># Filter data for today and the last 365 days</span>
silver_df = bronze_df.filter(
    (col(<span class="string">"date"</span>) >= date_sub(current_date(), 365)) & (col(<span class="string">"date"</span>) <= current_date())
)

<span class="datatype">silver_df</span> = <span class="datatype">silver_df</span>.<span class="function">dropDuplicates</span>().<span class="function">filter</span>(col(<span class="string">"status"</span>).<span class="function">isNotNull</span>())
<span class="datatype">silver_df</span> = <span class="datatype">silver_df</span>.<span class="function">repartition</span>(365, col("date"))
<span class="datatype">silver_df</span>.<span class="function">write</span>().<span class="keyword">format</span>(<span class="string">"delta"</span>).<span class="keyword">mode</span>(<span class="string">"overwrite"</span>).<span class="function">save</span>(<span class="keyword">silver_path</span>)


<span class="comment"># ----------- Gold Layer (Aggregated and Optimized Data) ------------------ #</span>
<span class="datatype">silver_df</span> = spark.<span class="function">read</span>().<span class="keyword">format</span>(<span class="string">"delta"</span>).<span class="function">load</span>(<span class="keyword">silver_path</span>)

<span class="comment"># Perform aggregations for reporting.</span>
<span class="datatype">gold_df</span>   = <span
class="datatype">silver_df</span>.<span class="function">groupBy</span>(<span
class="string">"category"</span>) 
                     .<span class="function">agg</span>( 
                          <span class="function">count</span>(<span class="string">"order_id"</span>).<span class="keyword">alias</span>(<span class="string">"total_orders"</span>), 
                          <span class="function">sum</span>(<span class="string">"sales_amount"</span>).<span class="keyword">alias</span>(<span class="string">"total_sales"</span>) 
                         ) 
<span class="datatype">gold_df</span> = <span class="datatype">gold_df</span>.<span class="function">repartition</span>(100, col("category"), col("date"))
<span class="datatype">gold_df</span>.<span class="function">write</span>().<span class="keyword">format</span>(<span class="string">"delta"</span>).<span class="keyword">mode</span>(<span class="string">"overwrite"</span>).<span class="function">save</span>(<span class="keyword">gold_path</span>)

<span class="keyword">spark.stop</span>()
    </code></pre>


    <hr>

<h1>PySpark Aggregation Tables</h1>

<h2>Data Description</h2>
<p>Dataset containing three columns: <strong>category</strong>, <strong>order_id</strong>, and <strong>sales_amount</strong>. The dataset is grouped by the <strong>category</strong> column, and we perform aggregation to count the total number of orders and sum up the sales amounts for each category.</p>

<h3>Original Dataset</h3>
<table class="comparison-table">
    <tr>
        <th>category</th>
        <th>order_id</th>
        <th>sales_amount</th>
    </tr>
    <tr>
        <td>Grocery</td>
        <td>1</td>
        <td>100</td>
    </tr>
    <tr>
        <td>Electronics</td>
        <td>2</td>
        <td>200</td>
    </tr>
    <tr>
        <td>Grocery</td>
        <td>3</td>
        <td>150</td>
    </tr>
    <tr>
        <td>Electronics</td>
        <td>4</td>
        <td>300</td>
    </tr>
    <tr>
        <td>Grocery</td>
        <td>5</td>
        <td>100</td>
    </tr>
</table>

<h3>Aggregated Result</h3>
<p>After performing the aggregation, the dataset is grouped by <strong>category</strong>, and we compute two new columns: <strong>total_orders</strong> and <strong>total_sales</strong>.</p>

<table class="comparison-table">
    <tr>
        <th>category</th>
        <th>total_orders</th>
        <th>total_sales</th>
    </tr>
    <tr>
        <td>Grocery</td>
        <td>3</td>
        <td>350</td>
    </tr>
    <tr>
        <td>Electronics</td>
        <td>2</td>
        <td>500</td>
    </tr>
</table>

  {% include footer.html %}

  </body>
</html>
