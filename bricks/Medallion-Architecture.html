---
---
{% include menu.html title="Medallion Architecture in Delta Lake" %}
<p><hr width=1000 align=left>

<table width="1000">
    <tr>
        <td>
            <h1>Medallion Architecture in Delta Lake</h1>

            <h3>Overview of Medallion Architecture</h3>
            <ul>
                <li>The Medallion Architecture is a layered approach used in Delta Lake to optimize data quality and performance as data progresses through various stages.
                It divides the data into three primary layers, referred to as <font color=red>Bronze, Silver, Gold</font> tiers, each representing different levels of data quality, transformation, and availability.
                This architecture is designed to ensure data consistency, facilitate complex analytics, and minimize the cost of managing big data.</li>
            </ul>

            <h3>Bronze Layer: Raw Data Ingestion</h3>
            <ul>
                <li>The <font color=red>Bronze layer</font> is where raw, unprocessed data is stored directly from source systems.</li>
                <li>This data is ingested in its original form and might include duplicates, errors, or incomplete records.</li>
                <li>In this layer, Delta Lake efficiently handles large-scale data ingestion from multiple formats like JSON, CSV, Parquet, or Avro.</li>
                <li>The primary purpose of this layer is to store the raw, unfiltered data for future processing, ensuring data traceability.</li>
            </ul>

            <h3>Silver Layer: Cleaned and Refined Data</h3>
            <ul>
                <li>The <font color=red>Silver layer</font> involves refining, cleaning, and transforming the raw data into a more structured form.</li>
                <li>At this stage, data undergoes transformations such as removing duplicates, handling missing values, and applying business logic to make the data more consistent and usable.</li>
                <li>This layer is where data quality improvements are implemented, making it ready for analytics and reporting.</li>
                <li>Common transformations include joining data from multiple sources and filtering or aggregating information.</li>
            </ul>

            <h3>Gold Layer: Aggregated and Optimized Data</h3>
            <ul>
                <li>The <font color=red>Gold layer</font> represents the final stage where the data is fully transformed, aggregated, and optimized for high-performance analytics.</li>
                <li>In this layer, data is typically denormalized and pre-aggregated for specific business use cases such as reporting, machine learning models, or advanced analytics.</li>
                <li>This layer often contains data that is used for dashboards, KPIs, and decision-making, providing insights based on the refined and validated data.</li>
                <li>The focus here is on reducing query latency and improving performance for end-users by leveraging pre-processed and ready-to-use data.</li>
            </ul>

            <h3>Benefits of the Medallion Architecture</h3>
            <ul>
                <li><strong>Data Quality:</strong> As data moves from the Bronze to Gold layer, its quality improves, which helps to ensure accurate reporting and analytics.</li>
                <li><strong>Data Governance:</strong> Each layer provides a clear separation of raw, intermediate, and final datasets, aiding in governance and lineage tracking.</li>
                <li><strong>Scalability:</strong> The architecture is highly scalable, supporting a range of data sizes from terabytes to petabytes.</li>
                <li><strong>Flexibility:</strong> The architecture can accommodate various data sources and formats, while allowing different teams to work on separate layers without conflicts.</li>
            </ul>

            <h3>Medallion Architecture in Practice</h3>
            <ul>
                <li>In real-world implementations, teams may have different sets of Bronze, Silver, and Gold layers for each business domain (e.g., sales, finance, operations).</li>
                <li>Data engineers typically work on the Bronze and Silver layers, while analysts and data scientists use the Gold layer for insights and model training.</li>
                <li>By adopting this architecture, organizations can ensure that data is ingested, processed, and made available for decision-making with minimal latency.</li>
            </ul>
        </td>
    </tr>
</table>

<p><hr width=1000 align=left>
        <h1>Medallion Architecture with Partitioning</h1>
    <pre><code class=language-python>
spark = SparkSession.builder \
  .appName("Medallion Architecture") \
  .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
  .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog") \
  .config("spark.executor.instances", "256") \
  .config("spark.sql.shuffle.partitions", "1024") \
  .getOrCreate()

# Paths for the Bronze, Silver, and Gold layers
bronze_path = "/mnt/delta/bronze"
silver_path = "/mnt/delta/silver"
gold_path   = "/mnt/delta/gold"

# ----------- Bronze Layer (Raw Data Ingestion) ----------------------------- #
raw_data = spark.read().format("json").load("/mnt/raw_data/")
raw_data = raw_data.repartition(1024)
raw_data.write().format("delta").mode("overwrite").save(bronze_path)


# ----------- Silver Layer (Data Cleaning and Transformation) --------------- #
bronze_df = spark.read().format("delta").load(bronze_path)

# Filter data for today and the last 365 days
silver_df = bronze_df.filter(
    (col("date") >= date_sub(current_date(), 365)) & (col("date") <= current_date())
)

silver_df = silver_df.dropDuplicates().filter(col("status").isNotNull())
silver_df = silver_df.repartition(365, col("date"))
silver_df.write().format("delta").mode("overwrite").save(silver_path)


# ----------- Gold Layer (Aggregated and Optimized Data) ------------------ #
silver_df = spark.read().format("delta").load(silver_path)

# Perform aggregations for reporting.
gold_df   = silver_df.groupBy("category") 
                     .agg( 
                          count("order_id").alias("total_orders"), 
                          sum("sales_amount").alias("total_sales") 
                         ) 
gold_df = gold_df.repartition(100, col("category"), col("date"))
gold_df.write().format("delta").mode("overwrite").save(gold_path)

spark.stop()    
</code></pre>

<p><hr width=1000 align=left>
<h1>PySpark Aggregation Tables</h1>

<h2>Data Description</h2>
<p>Dataset containing three columns: <strong>category</strong>, <strong>order_id</strong>, and <strong>sales_amount</strong>. The dataset is grouped by the <strong>category</strong> column, and we perform aggregation to count the total number of orders and sum up the sales amounts for each category.</p>

<h3>Original Dataset</h3>
<table class="comparison-table">
    <tr>
        <th>category</th>
        <th>order_id</th>
        <th>sales_amount</th>
    </tr>
    <tr>
        <td>Grocery</td>
        <td>1</td>
        <td>100</td>
    </tr>
    <tr>
        <td>Electronics</td>
        <td>2</td>
        <td>200</td>
    </tr>
    <tr>
        <td>Grocery</td>
        <td>3</td>
        <td>150</td>
    </tr>
    <tr>
        <td>Electronics</td>
        <td>4</td>
        <td>300</td>
    </tr>
    <tr>
        <td>Grocery</td>
        <td>5</td>
        <td>100</td>
    </tr>
</table>

<h3>Aggregated Result</h3>
<p>After performing the aggregation, the dataset is grouped by <strong>category</strong>, and we compute two new columns: <strong>total_orders</strong> and <strong>total_sales</strong>.</p>

<table class="comparison-table">
    <tr>
        <th>category</th>
        <th>total_orders</th>
        <th>total_sales</th>
    </tr>
    <tr>
        <td>Grocery</td>
        <td>3</td>
        <td>350</td>
    </tr>
    <tr>
        <td>Electronics</td>
        <td>2</td>
        <td>500</td>
    </tr>
</table>

  {% include footer.html %}

  </body>
</html>
