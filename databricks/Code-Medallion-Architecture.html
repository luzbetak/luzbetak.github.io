---
---
{% include menu.html title="Medallion Architecture with 256 Node Cluster" %}


<body>
        <h1>Medallion Architecture with 256 Node Cluster</h1>

    <pre><code>
<span class="comment"># Initialize Spark session with Delta support</span>
<span class="keyword">spark</span> = SparkSession.builder \
    .<span class="function">appName</span>(<span class="string">"Medallion Architecture"</span>) \
    .<span class="keyword">config</span>(<span class="string">"spark.sql.extensions"</span>, <span class="string">"io.delta.sql.DeltaSparkSessionExtension"</span>) \
    .<span class="keyword">config</span>(<span class="string">"spark.sql.catalog.spark_catalog"</span>, <span class="string">"org.apache.spark.sql.delta.catalog.DeltaCatalog"</span>) \
    .<span class="keyword">config</span>(<span class="string">"spark.executor.instances"</span>, <span class="string">"256"</span>) \
    .<span class="keyword">config</span>(<span class="string">"spark.sql.shuffle.partitions"</span>, <span class="string">"1024"</span>) \
    .<span class="function">getOrCreate</span>()

<span class="comment"># Paths for the Bronze, Silver, and Gold layers</span>
<span class="keyword">bronze_path</span> = <span class="string">"/mnt/delta/bronze"</span>
<span class="keyword">silver_path</span> = <span class="string">"/mnt/delta/silver"</span>
<span class="keyword">gold_path</span>   = <span class="string">"/mnt/delta/gold"</span>

<span class="comment"># ----------- Bronze Layer (Raw Data Ingestion) ----------------------------- #</span>
<span class="keyword">raw_data</span> = spark.<span class="function">read</span>().<span class="keyword">format</span>(<span class="string">"json"</span>).<span class="function">load</span>(<span class="string">"/mnt/raw_data/"</span>)

<span class="keyword">raw_data</span> = <span class="keyword">raw_data</span>.<span class="function">repartition</span>(256)

<span class="keyword">raw_data</span>.<span class="function">write</span>().<span class="keyword">format</span>(<span class="string">"delta"</span>).<span class="keyword">mode</span>(<span class="string">"overwrite"</span>).<span class="function">save</span>(<span class="keyword">bronze_path</span>)

<span class="comment"># ----------- Silver Layer (Data Cleaning and Transformation) --------------- #</span>
<span class="datatype">bronze_df</span> = spark.<span class="function">read</span>().<span class="keyword">format</span>(<span class="string">"delta"</span>).<span class="function">load</span>(<span class="keyword">bronze_path</span>)

<span class="comment"># Filter data for today and the last 7 days</span>
silver_df = bronze_df.filter(
    (col(<span class="string">"date"</span>) >= date_sub(current_date(), 7)) & (col(<span class="string">"date"</span>) <= current_date())
)

<span class="comment"># Drop Duplicates</span>
<span class="datatype">silver_df</span> = <span class="datatype">silver_df</span>.<span class="function">dropDuplicates</span>().<span class="function">filter</span>(col(<span class="string">"status"</span>).<span class="function">isNotNull</span>())

<span class="datatype">silver_df</span> = <span class="datatype">silver_df</span>.<span class="function">repartition</span>(256, col("date"))
<span class="datatype">silver_df</span>.<span class="function">write</span>().<span class="keyword">format</span>(<span class="string">"delta"</span>).<span class="keyword">mode</span>(<span class="string">"overwrite"</span>).<span class="function">save</span>(<span class="keyword">silver_path</span>)

<span class="comment"># ----------- Gold Layer (Aggregated and Optimized Data) ------------------ #</span>
<span class="datatype">silver_df</span> = spark.<span class="function">read</span>().<span class="keyword">format</span>(<span class="string">"delta"</span>).<span class="function">load</span>(<span class="keyword">silver_path</span>)
<span class="datatype">gold_df</span>   = <span
class="datatype">silver_df</span>.<span class="function">groupBy</span>(<span
class="string">"category"</span>) 
                     .<span class="function">agg</span>( 
                          <span class="function">count</span>(<span class="string">"order_id"</span>).<span class="keyword">alias</span>(<span class="string">"total_orders"</span>), 
                          <span class="function">sum</span>(<span class="string">"sales_amount"</span>).<span class="keyword">alias</span>(<span class="string">"total_sales"</span>) 
                         ) 
<span class="datatype">gold_df</span> = <span class="datatype">gold_df</span>.<span class="function">repartition</span>(365, col("date"), col("category"))
<span class="datatype">gold_df</span>.<span class="function">write</span>().<span class="keyword">format</span>(<span class="string">"delta"</span>).<span class="keyword">mode</span>(<span class="string">"overwrite"</span>).<span class="function">save</span>(<span class="keyword">gold_path</span>)




<span class="keyword">spark.stop</span>()
    </code></pre>


    <hr>

<h1>PySpark Aggregation Tables</h1>

<h2>Data Description</h2>
<p>Dataset containing three columns: <strong>category</strong>, <strong>order_id</strong>, and <strong>sales_amount</strong>. The dataset is grouped by the <strong>category</strong> column, and we perform aggregation to count the total number of orders and sum up the sales amounts for each category.</p>

<h3>Original Dataset</h3>
<table class="comparison-table">
    <tr>
        <th>category</th>
        <th>order_id</th>
        <th>sales_amount</th>
    </tr>
    <tr>
        <td>Grocery</td>
        <td>1</td>
        <td>100</td>
    </tr>
    <tr>
        <td>Electronics</td>
        <td>2</td>
        <td>200</td>
    </tr>
    <tr>
        <td>Grocery</td>
        <td>3</td>
        <td>150</td>
    </tr>
    <tr>
        <td>Electronics</td>
        <td>4</td>
        <td>300</td>
    </tr>
    <tr>
        <td>Grocery</td>
        <td>5</td>
        <td>100</td>
    </tr>
</table>

<h3>Aggregated Result</h3>
<p>After performing the aggregation, the dataset is grouped by <strong>category</strong>, and we compute two new columns: <strong>total_orders</strong> and <strong>total_sales</strong>.</p>

<table class="comparison-table">
    <tr>
        <th>category</th>
        <th>total_orders</th>
        <th>total_sales</th>
    </tr>
    <tr>
        <td>Grocery</td>
        <td>3</td>
        <td>350</td>
    </tr>
    <tr>
        <td>Electronics</td>
        <td>2</td>
        <td>500</td>
    </tr>
</table>

    <hr>

    <ol>
        <li><h3>Initialization and Cluster Configuration</h3>
            <ul>
                <li>Initialize the Spark session and configure it to distribute tasks across 256 nodes, setting appropriate executor cores and shuffle partitions.
                    <pre><code><span class="comment"># Initialize Spark session with Delta support, configured for 256 nodes</span>
<span class="keyword">spark</span> = SparkSession.builder \
    .<span class="function">appName</span>(<span class="string">"Medallion Architecture"</span>) \
    .<span class="keyword">config</span>(<span class="string">"spark.sql.extensions"</span>, <span class="string">"io.delta.sql.DeltaSparkSessionExtension"</span>) \
    .<span class="keyword">config</span>(<span class="string">"spark.sql.catalog.spark_catalog"</span>, <span class="string">"org.apache.spark.sql.delta.catalog.DeltaCatalog"</span>) \
    .<span class="keyword">config</span>(<span class="string">"spark.executor.instances"</span>, <span class="string">"256"</span>) \
    .<span class="keyword">config</span>(<span class="string">"spark.executor.cores"</span>, <span class="string">"4"</span>) \
    .<span class="keyword">config</span>(<span class="string">"spark.sql.shuffle.partitions"</span>, <span class="string">"1024"</span>) \
    .<span class="function">getOrCreate</span>()</code></pre>
                </li>
            </ul>
        </li>

        <li><h3>Bronze Layer: Raw Data Ingestion</h3>
            <ul>
                <li>Step 1: Load raw data into the Bronze layer from a JSON source.
                    <pre><code><span class="keyword">raw_data</span> = spark.<span class="function">read</span>().<span class="keyword">format</span>(<span class="string">"json"</span>).<span class="function">load</span>(<span class="string">"/mnt/raw_data/"</span>)</code></pre>
                </li>
                <li>Step 2: Repartition the raw data into 256 partitions, distributing it across 256 nodes.
                    <pre><code><span class="keyword">raw_data</span> = <span class="keyword">raw_data</span>.<span class="function">repartition</span>(256)</code></pre>
                </li>
                <li>Step 3: Write the raw data to the Bronze Delta table.
                    <pre><code><span class="keyword">raw_data</span>.<span class="function">write</span>().<span class="keyword">format</span>(<span class="string">"delta"</span>).<span class="keyword">mode</span>(<span class="string">"overwrite"</span>).<span class="function">save</span>(<span class="keyword">bronze_path</span>)</code></pre>
                </li>
            </ul>
        </li>

        <li><h3>Silver Layer: Data Cleaning and Transformation</h3>
            <ul>
                <li>Step 4: Read data from the Bronze layer.
                    <pre><code><span class="datatype">bronze_df</span> = spark.<span class="function">read</span>().<span class="keyword">format</span>(<span class="string">"delta"</span>).<span class="function">load</span>(<span class="keyword">bronze_path</span>)</code></pre>
                </li>
                <li>Step 5: Clean the data by removing duplicates and filtering out null values.
                    <pre><code><span class="datatype">silver_df</span> = <span class="datatype">bronze_df</span>.<span class="function">dropDuplicates</span>().<span class="function">filter</span>(col(<span class="string">"status"</span>).<span class="function">isNotNull</span>())</code></pre>
                </li>
                <li>Step 6: Repartition the cleaned data across 256 partitions for parallelism.
                    <pre><code><span class="datatype">silver_df</span> = <span class="datatype">silver_df</span>.<span class="function">repartition</span>(256)</code></pre>
                </li>
                <li>Step 7: Write the cleaned data to the Silver Delta table.
                    <pre><code><span class="datatype">silver_df</span>.<span class="function">write</span>().<span class="keyword">format</span>(<span class="string">"delta"</span>).<span class="keyword">mode</span>(<span class="string">"overwrite"</span>).<span class="function">save</span>(<span class="keyword">silver_path</span>)</code></pre>
                </li>
            </ul>
        </li>

        <li><h3>Gold Layer: Aggregated and Optimized Data</h3>
            <ul>
                <li>Step 8: Read data from the Silver layer.
                    <pre><code><span class="datatype">silver_df</span> = spark.<span class="function">read</span>().<span class="keyword">format</span>(<span class="string">"delta"</span>).<span class="function">load</span>(<span class="keyword">silver_path</span>)</code></pre>
                </li>
                <li>Step 9: Perform aggregations for reporting.
                    <pre><code><span class="datatype">gold_df</span> = <span class="datatype">silver_df</span>.<span class="function">groupBy</span>(<span class="string">"category"</span>) \
    .<span class="function">agg</span>(<span class="function">count</span>(<span class="string">"order_id"</span>).<span class="keyword">alias</span>(<span class="string">"total_orders"</span>), \
        <span class="function">sum</span>(<span class="string">"sales_amount"</span>).<span class="keyword">alias</span>(<span class="string">"total_sales"</span>))</code></pre>
                </li>
                <li>Step 10: Repartition the aggregated data for optimal distribution.
                    <pre><code><span class="datatype">gold_df</span> = <span class="datatype">gold_df</span>.<span class="function">repartition</span>(256)</code></pre>
                </li>
                <li>Step 11: Write the aggregated data to the Gold Delta table.
                    <pre><code><span class="datatype">gold_df</span>.<span class="function">write</span>().<span class="keyword">format</span>(<span class="string">"delta"</span>).<span class="keyword">mode</span>(<span class="string">"overwrite"</span>).<span class="function">save</span>(<span class="keyword">gold_path</span>)</code></pre>
                </li>
            </ul>
        </li>

        <li><h3>Shutdown</h3>
            <ul>
                <li>Stop the Spark session to release resources.
                    <pre><code><span class="keyword">spark.stop</span>()</code></pre>
                </li>
            </ul>
        </li>
    </ol>


  {% include footer.html %}

  </body>
</html>
