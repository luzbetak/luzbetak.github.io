[
    {
        "id": 1,
        "title": "TF-IDF.html",
        "content": "tf idf another breakdown column content convert corpus data decimals doc docs document documents entire example feature frequency high higher highest idf import importance important inverse learning limit low lower machine many matrix model multiple names particular practice prettytable python range ranking relevant result row rows sample score scores specific summary table term terms text tf tfidfvectorizer theory uniqueness upper value values vectorizer word words",
        "url": "/TF-IDF.html"
    },
    {
        "id": 2,
        "title": "Retrieval-Augmented-Generation.html",
        "content": "retrieval augmented generation accurate algorithm another augment augmented base bert build chatbot components conn contextual create database datasets dimensional document documents embeddings engines extension external generate generated generation generator gpt high id import indexing information informed insert install key knowledge large limit management model models multiple necessary nodes optimization order outputs parallel performance pgvector pgvectorscale postgres postgresql primary process prompt python queries query question rag references relevant repositories response responses retrieval retrieved scale search searches sentencetransformer serial similarity solution step storage store systems table tasks text tokenizer transformers tutorial user values vector vectors",
        "url": "/Retrieval-Augmented-Generation.html"
    },
    {
        "id": 3,
        "title": "Tensors-Machine-Learning.html",
        "content": "tensors machine learning access additional array average building channels code color column complex computation computations compute data deep depth dimensional dimensions efficient element elements essence even example excellent foundation frameworks function functionality functions fundamental generalization gpus high images import index indexing key learning library list machine matrices matrix mean models multi multidimensional ndarrays np number numbers numerical numpy operation operations output points powerful print python pytorch row simple single solid spaces specific structure sum support syntax table tensor tensorflow tensors total training us value values vector vectors words",
        "url": "/Tensors-Machine-Learning.html"
    },
    {
        "id": 4,
        "title": "bm25-probabilistic-information-retrieval-model.html",
        "content": "bm25 probabilistic information retrieval model account algorithm algorithms application average b based best called cases collection components content controlling corpus customization databases default differences document documents dynamic effective engine engines entire family fewer formula frequency fully function given handling high higher highly idf impact importance influence information inverse key keyword known length less library long longer many matching measures model models modern needs normalization normalizes nt number often overemphasis parameter parameters powerful probabilistic q query ranking rarity real relevance repetition retrieval saturated saturation score search shorter size specific standard systems tasks term terms text tf total traditional tuning use value variant weight well world xapian",
        "url": "/bm25-probabilistic-information-retrieval-model.html"
    },
    {
        "id": 5,
        "title": "Random-Forest-Classifier-Model.html",
        "content": "random forest classifier model account accuracy address approach authentication automation balance billing card case categories category charge classification classifier classifieri clf code collection create credentials cryptocurrency customer damaged data date decision delivery depth details device df dictionary different discount either email factor feature features final forest generalization generator gift history hyperparameters idf import incoming individual information input internal invoice item labels leaf length lists login manual maximum method methods minimum missing model nearest new node notifications number numerical options order output outstanding overfitting pandas parameter password payment pd pin plan policy predicted prediction predictions prettytable product proportion purchase python queries query question questions random refund remaining reproducibility return samples seed set shipping split step store subscription subset support supported table target task technical test testing text textual tf tfidfvectorizer train training tree trees two user value various vectorize vectorizer warranty",
        "url": "/Random-Forest-Classifier-Model.html"
    },
    {
        "id": 6,
        "title": "Scikit-learn.html",
        "content": "scikit learn accuracy actions actual algorithms allows analysis apis auc beginners best box bunch categorical classifier clf code comparison corresponding data dataset datasets dbscan decision dictionary dimensionality documented efficient external features files flowers following forest forests function good grid high identical import initializes integration iris joblib k key label labels later learning length libraries library linear load loads machine machines matplotlib metrics missing model modeling models normalization numpy object open output overview pandas pca performance persistence petal pickle points popular precision predicted predictions predicts preprocessing print professionals python random range reduction regression results roc sample samples scaling science scikit scipy search selection sepal set sets setup simple sne source specific split summary supervised support svm target test testing tools top toy train trained training trees unsupervised use used validation values variables variety vector vs well wide widely width yes",
        "url": "/Scikit-learn.html"
    },
    {
        "id": 7,
        "title": "Vector-Database.html",
        "content": "vector database abnormal accuracy ai angular annoy annoyindex anomalies anomaly api apis applications approximate associated audio behavior bert billions cases characteristics classification client clustering code collection common connect connection content control count cpu critical data database databases datasets dbscan dense detection dimension dimensional dimensionality display distance distances documents driven ecosystem efficiency efficient embedding embeddings environments essential euclidean event example explanation external f facebook faiss fast faster feature features file first flat focuses format friendly full function gcp generated gpt gpu high hnsw hosting id identify ids image images import index initialization insert inserts install integration item items ivf k key keywords labels lancedb language large latency learning library local low machine management manhattan match meaning means memory metadata metric metrics ml models modern natural nearest need needs neighbor neighbors new nlp nn np numerical numpy open outliers overview path performance pinecone pip pipelines points processing production products python queries query querying random randomly range real recommend recommendation regression result results retrieval retrieve role scalability scale scales scenarios search searches semantic semantically services similar similarity situations small source space specialized specified spotify steps storage store systems table tasks text throughput time top traditional transaction tree type types unusual upserting usage use user users using various vec vector vectors version visual wide workloads world",
        "url": "/Vector-Database.html"
    },
    {
        "id": 8,
        "title": "Stable-Diffusion-Web-UI.html",
        "content": "stable diffusion web ui acceleration browser cd chip clone command cuda dependencies diffusion error export following git gpu index install local mac message mps optional pip press python repository run server skip stable terminal test torch torchaudio torchvision ui url users web webui",
        "url": "/Stable-Diffusion-Web-UI.html"
    },
    {
        "id": 9,
        "title": "Keras.html",
        "content": "keras accessible accuracy activation adam algorithms analysis api artificial backpropagation basic best biases binary blocks building calculating case channel channels churn class classes classification cnn cnns cntk code colored compile complex complexities complexity components computation computational connected connections consistent convolution convolutional core corners correct cpu customer cycle data decision deep dense detection developers diagnosis differences different digit digits dimensional dimensions direction ease edges either error example facial faster feature features feedback feedforward filters final flatten flattening fnn forward fraud fully function functional functions generation gpu gpus grayscale grid handwriting hardware hidden hierarchies high highly image images import important information input keras kernels key labels layer layers learning level library linear linearity load loops loss low lstm many map maps max medical metrics minimal mnist model models multi network networks neural node nodes non normalize number numpy object one open operations optimizer optimizers output overview parameters part patterns performance pixel pixels platform pooling prediction predictions probabilities process processing propagation recognition rectified reinforcement relu reshape rgb scaler sequential sets simple size softmax source spatial specialized stack standardscaler structure structured summary support synthetic tabular task tasks tensorflow testing text textures theano top training type unit use variety vector video weights x",
        "url": "/Keras.html"
    },
    {
        "id": 10,
        "title": "Gunning-Fog-Index.html",
        "content": "gunning fog index account algorithms analysis average avoid calculation code complex content count creation def division document education english example explanation expressions first fog following formal formula function general given gunning higher implementation import index language length levels marks natural nlp number output patterns percentage period processing punctuation readability readership reading regular return score sentence sentences steps syllables test text texts three usage vowel vowels way word words writing years zero",
        "url": "/Gunning-Fog-Index.html"
    },
    {
        "id": 11,
        "title": "PyTorch-Sentiment-Analysis-Model.html",
        "content": "pytorch sentiment analysis model accuracy acting analysis apply base batch bcewithlogitsloss bertmodel berttokenizer book build class classification complete compute connected convert criterion dataloader dataset decent define dimension direction epoch evaluation every examples existing experience extra false film fully function great horrible idx import inference input labels layers linearity load logits loop loss masterpiece minute mode model module movie negative nn non optimizer optional output outputs performance performances plot positive prediction predictions prettytable print python raw report return save saved second sentiment sentimentclassifier sets sigmoid split statement statements story storytelling table terrible test testing text textdataset texts threshold time tokenizer tokens torch train trained training transformers truncation two use values waste watch worst year",
        "url": "/PyTorch-Sentiment-Analysis-Model.html"
    },
    {
        "id": 12,
        "title": "python-whoosh.html",
        "content": "python whoosh better brown changes content def define directory doc document documents dog example fast fox id import index indexing lazy library path print pure python query queryparser quick result results schema search stemminganalyzer text title whoosh writer",
        "url": "/python-whoosh.html"
    },
    {
        "id": 13,
        "title": "Hugging-Face-Machine-Learning.html",
        "content": "hugging face machine learning access account api approval cli command dev download ensure face forest hfapi hugging huggingface import issues learning line login machine maintainers model necessary note owners page permissions read repository restricted retry script token verify",
        "url": "/Hugging-Face-Machine-Learning.html"
    },
    {
        "id": 14,
        "title": "Time-Complexity-Big-O-Notation.html",
        "content": "time complexity big o notation access addition adjacency algorithm array average avl b balance balanced bfs big binary black brute bst bubble case cases certain children collisions common complexities complexity computer constant data databases deletion deletions design division double e edges efficiency efficient element elements example execution extra factor file force hash head height index indexing input insertion insertions keys leaf least level linear linearithmic list logarithmic loop luzbetak max memory merge merging min minimum much n nature nested new nodes notation number operations performance permutations priority problem process properties queue rebalancing red resizing retrieval root runtime salesman scenario search selection set size sort sorted space splitting step storage structure structures systems table time traveling tree trees use v vertices way worst",
        "url": "/Time-Complexity-Big-O-Notation.html"
    },
    {
        "id": 15,
        "title": "PyTorch.html",
        "content": "pytorch acceleration apply arrays audio autograd automatic backward built class classes common computation computational compute computer connected criterion crossentropyloss custom dataset datasets debug deep developers differentiation digits dimensional dynamic epoch extensibility faster features final flexible fully function gpu gradients graphs image import inputs key labels language layer layers learning libraries library load loop loss machine mnist models module multi natural network networks neural nlp nn numpy open optim optimization optimize output outputs platform pre preprocess processing pytorch relu researchers simple source speech strong support tasks techniques tensors torch torchaudio torchtext torchvision totensor training trainloader transform variety various vision wide x zero",
        "url": "/PyTorch.html"
    },
    {
        "id": 16,
        "title": "Python-Syntax-Highlighting.html",
        "content": "python syntax highlighting age b bash cd computer def desc echo fmt golang highlighting int luzbetak mkdir name order python return select sql syntax users world",
        "url": "/Python-Syntax-Highlighting.html"
    },
    {
        "id": 17,
        "title": "Managed-External-Live-Tables.html",
        "content": "managed external live tables actual automated automation aws azure batch blob case checks cloud create data databricks datasets dbfs def default delta dependencies differences dlt etl example execution external feature file files framework fully hdfs id import ingestion int internal key lifecycle live location managed managing metadata monitoring name output persistent pipeline pipelines processing quality real return shared storage streaming string system table tables tasks temporary time transformation underlying use users workflows",
        "url": "/bricks/Managed-External-Live-Tables.html"
    },
    {
        "id": 18,
        "title": "PySpark-Coding-Examples.html",
        "content": "pyspark coding examples age aggregate aggregation average avg back based bob categories category cathy centralized clause code col column commands computer condition count csv customers data databricks dataframe dataframes def default defined delta department desc df distinct duplicate email example exercises explode false file fill filter format formats function greater group guide handling id import introduction lake lakes let limit loading luzbetak missing name names none number occurrences operation order orderby parquet people prefix price pyspark queries read records repository result rows salaries salary sales sample scale select show spark sparksession specific split sql stringtype structured sum text top total transformation transformations two udf unique unstructured user value values various word words world write writing",
        "url": "/bricks/PySpark-Coding-Examples.html"
    },
    {
        "id": 19,
        "title": "RDBMS-Schemas.html",
        "content": "rdbms schemas central charts child clear common complex complexity connections constellation data database databases denormalized dimension dimensions fact faster fewer flat foundational galaxy hierarchical integrity joins management many marts multiple needs network non organizational organizes parent performance queries query rdbms redundancy related relational relationship relationships schema schemas several simple simpler single snowflake specific star structure systems table tables tree warehouses",
        "url": "/bricks/RDBMS-Schemas.html"
    },
    {
        "id": 20,
        "title": "PySpark-Data-Streaming.html",
        "content": "pyspark data streaming abstraction api application averages backpressure based batch batches capabilities checkpointing checkpoints cluster code computation consistent continuous core counts data dataframes dataset datasets declarative development different distributed dstream dstreams ease ecosystems evolution failures fault flexibility flume frames handles handling hardware hdfs information input integration kafka kinesis larger live logs loss lost metrics micro network node nodes operations original overwhelming patterns period process processing pyspark rate rdd rdds real resilience resilient resources running scalability sensor sliding small sockets source sources spark specific sql state stateful stream streaming streams structured support system tcp time tolerance transformations trends tweets various volumes window",
        "url": "/bricks/PySpark-Data-Streaming.html"
    },
    {
        "id": 21,
        "title": "Databricks-Delta-Lake.html",
        "content": "databricks delta lake acid aggregated analysis approach architecture audits availability batch big broad bronze cleaned collaboration concurrent connector consistency controlled copy data databricks datasets debugging delta design durability ecosystem efficient external failures fast feature flexibility flink given handling historical isolation lake large management massive medallion metadata modifications need open optimized organizations partners platforms point presto processing protocol quality queries raw refined reliability scalable scale scenarios seamless secure sharing single streaming support tiers time tools transactions travel trino types unified users various versioning versions workloads",
        "url": "/bricks/Databricks-Delta-Lake.html"
    },
    {
        "id": 22,
        "title": "RDBMS-Snowflake-Schema.html",
        "content": "rdbms snowflake schema additional advanced approach attributes central characteristics complex complexity cost costs data database design difference differences dimension dimensions duplicated environments example extension fact fewer higher increased indexing integrity joins key layers level levels minimizing modeling multiple need normalization normalized normalizing performance piece priority process queries query reduced redundancy related relational relationships scenarios schema separate several shape single slower snowflake space star storage structure structured sub table tables techniques usage variation warehouses warehousing year",
        "url": "/bricks/RDBMS-Snowflake-Schema.html"
    },
    {
        "id": 23,
        "title": "etl-pipeline.html",
        "content": "etl pipeline accuracy additional aggregation analysis apis application applying averages business calculations cleaning cloud common connectivity consistency context conversion convert counts csv currencies data database databases date destination different downtime duplicates enhancing enrichment ensuring errors etl extract extraction failures files format formats full incremental information integrity irrelevant issues lake large load loading logic missing needs optimization organization performance process reference resource retries rules services sources specific structure summarizing sums system tables target transform transformed usage values various volumes warehouse xml",
        "url": "/bricks/etl-pipeline.html"
    },
    {
        "id": 24,
        "title": "Databricks-PySpark.html",
        "content": "databricks pyspark abstractions access acid action aggregation algorithms allocation analysis analysts analytics apache api applications aws azure based big business capabilities cases cloud cluster clusters code collaboration collaborative collect collections complexity computation computing count csv data databases databricks dataframe dataframes datasets deep delta deployment df distributed dive efficiency engineers environment etl evaluation example execution experiment extract fault features file fosters full fundamental gcp handling high import insights intelligence iterative key lake large layer lazy learning level leverage load machine machines management manipulation manner members memory metadata mlflow mllib model models multiple notebook notebooks open operations optimization overview pandas parallel performance pipelines platform process processing pyspark python queries rdds real resilient resource resources results scalability scalable scale scientists services session sharing source spark sparksession storage stream streaming structure structured system tasks team time tolerance top tracking transactions transformation true use user users visualizations workload workloads",
        "url": "/bricks/Databricks-PySpark.html"
    },
    {
        "id": 25,
        "title": "PySpark-Pivot-Table.html",
        "content": "pyspark pivot table analytics application categorical code column columns combination context data dataframe df dictionaries digestible east employee explanation following format functions github import information list luzbetak multiple new one output overview pages pivot pivoted provided purposes pyspark region reporting sales sample something south spark sparksession sum table tool unique using value values",
        "url": "/bricks/PySpark-Pivot-Table.html"
    },
    {
        "id": 26,
        "title": "RDBMS-Star-Schema.html",
        "content": "rdbms star schema advantages agegroup amounts analysis attributes central commerce components customer customerid customername data database date dateid dates de descriptive design details dimension e efficient example fact facts flexibility foreign increased joins keys limited links location month names normalization number popular product productid quantitative quantities quarter queries query rdbms region requirements resemblance sales schema simple simplicity star storage store storename table tables warehouse warehousing year",
        "url": "/bricks/RDBMS-Star-Schema.html"
    },
    {
        "id": 27,
        "title": "PySpark-SQL-Functions-Parquet.html",
        "content": "pyspark sql functions parquet age aggregate aggregation average avg back based bob categories category cathy centralized clause code col column commands condition count csv customers data databricks dataframe dataframes def default defined delta department desc df distinct duplicate email example explode false file fill filter format formats function functions greater group guide handling id import introduction lake lakes let limit loading missing name names none number occurrences operation order orderby parquet people prefix price pyspark queries read records repository result rows salaries salary sales sample scale select show spark sparksession specific split sql stringtype structured sum text top total transformation transformations two udf unique unstructured user value values various word words world write writing",
        "url": "/bricks/PySpark-SQL-Functions-Parquet.html"
    },
    {
        "id": 28,
        "title": "Medallion-Architecture.html",
        "content": "medallion architecture accurate advanced aggregated aggregation aggregations analysts analytics approach architecture availability avro benefits big bronze business cases category cleaning clear column columns common complex conflicts consistency cost csv dashboards data dataset datasets days decision delta description different domain duplicates electronics end engineers errors facilitate filter final flexibility focus form formats future gold governance grocery high implementations improvements incomplete information ingestion insights json kpis lake large last latency layer layered layers learning levels lineage logic machine making medallion minimal missing model models multiple new number operations optimized orders organizations original overview parquet partitioning performance petabytes practice primary processing purpose pyspark quality query range raw real records refined refining reporting result scalability scale scientists separate separation sets silver sizes source sources spark specific stage stages structured systems tables teams terabytes three tiers today total traceability tracking training transformation transformations two unfiltered unprocessed use users validated values various world",
        "url": "/bricks/Medallion-Architecture.html"
    },
    {
        "id": 29,
        "title": "Medallion-Architecture-Partitioning-Code.html",
        "content": "medallion architecture partitioning code agg aggregated aggregation aggregations alias architecture bronze category cleaning col column columns config count data dataset days deltacatalog deltasparksessionextension description dropduplicates electronics filter format getorcreate gold grocery groupby ingestion isnotnull last layer layers load medallion mode new node number optimized orders partitioning paths pyspark raw repartition reporting result save silver spark tables three today total transformation two",
        "url": "/bricks/Medallion-Architecture-Partitioning-Code.html"
    },
    {
        "id": 30,
        "title": "Managed-External-Tables.html",
        "content": "managed external tables case cases control data database delta directory external ideal lake lifecycle location managed management metadata physical specified storage system systems table tables unmanaged use user",
        "url": "/bricks/Managed-External-Tables.html"
    },
    {
        "id": 31,
        "title": "Column-Shuffle-Repartition.html",
        "content": "column shuffle repartition aggregations alternatives balance balancing case category cluster col column data default efficiency efficient equal example filtering following full goal grouping intention joins large later load logic multiple nodes number operations optimized oversized parallel partition partitions perfectly processing pyspark reasonable repartition repartitioning rows share shuffle shuffling smaller spark specific specified splits syntax value values works",
        "url": "/bricks/Column-Shuffle-Repartition.html"
    },
    {
        "id": 32,
        "title": "Optimizing-Join-Queries.html",
        "content": "optimizing join queries accessed active adequate allocation amount analysis anomalies architectures batch batches bottlenecks buffer cache check clause columns common complex composite condition conditions considerations constraints correct cost costly criterion ctes data database datasets date defragmentation denormalization design different dimension disk disks efficient enable environment example excessive execution expensive explain expressions fact faster files filter filtering filters flexible foreign fragmentation frequently full functions hardware histograms incorrect increased index indexed indexes indexing infrastructure inner insights insufficient join joins key large left legacy less limited loop maintenance management materialized memory merge method methods model monitoring multiple mysql need nested old older ones operation operations optimization optimize optimizing oracle order parallel partition partitioning parts performance plan pools potential processing processors proper pruning queried queries query redundancy redundant region regular regularly repeated resources results retrieval rewrite rewriting scalability scans schema selective separate simpler size smaller solutions specific ssds star statistics steps storage subqueries sufficient summary system table tables tasks techniques time tools type types unnecessary usage use views volume warehouse warehousing write",
        "url": "/bricks/Optimizing-Join-Queries.html"
    },
    {
        "id": 33,
        "title": "Relational-Databases.html",
        "content": "relational databases accuracy acid advantages algebra analysis analytical analytics another apis atomicity attribute attributes benefits better business category central centralized clear codd column columns complex compliance comprehensive concepts consistency constraints current data database databases datasets decision denormalized design differences dimension durability edgar enforced ensures entities etl extract fact fast features files finance flat foreign functions heavy historical identifier indexing integrity intelligence isolation key keys language large load making managing marts multidimensional multiple normalized nothing olap oltp one online operational operations performance predefined primary process processing purposes queries query querying reads record records redundancy reference relational relations relationships reporting row rows sales schema simple single slice snowflake source sources specific sql star state stores structure structured subsets table tables target techniques theory time transaction transactional transactions transformed trend truth unique users valid various view volumes warehouse warehouses warehousing writes",
        "url": "/bricks/Relational-Databases.html"
    },
    {
        "id": 34,
        "title": "PySpark-Lazy-Evaluation.html",
        "content": "pyspark lazy evaluation ability action actions actual acyclic amount benefits calculations cluster collect complex computation concept count dag data dataframe deferred directed distributed driver efficient entire environments evaluation example examples execution external fewer filter filtering final graph intermediate jobs key lambda large lazy logical manner map mapping memory necessary new operations optimization optimizations performance pipelines plan point points print processing program pyspark rdd resource resources result results saveastextfile scalable scale sequence several small spark steps storage subset transformations trigger unnecessary usage x",
        "url": "/bricks/PySpark-Lazy-Evaluation.html"
    },
    {
        "id": 35,
        "title": "Delta-Live-Tables.html",
        "content": "delta live tables acid analytics automate automatic cases checks clean cleaned col complex constraints creation data databricks declarative def define delta dependencies dependency development dlt ease efficiency enforce enforcement entire etl example execution failure features flexibility framework handling health immediate import incremental ingest ingestion key lake learning lifecycle lineage live machine managed management manual monitoring new observability operational optimizations orchestration output overhead performance pipeline pipelines processing quality raw real return schema simplified simplifies sources streaming supports syntax tables time tools top tracking transactions transformation transformations travel use valid visibility way workflow workloads",
        "url": "/bricks/Delta-Live-Tables.html"
    },
    {
        "id": 36,
        "title": "PySpark-Handling-Missing-Data.html",
        "content": "pyspark handling missing data action algorithms analysis analytics apache api applications backward big binary building cluster col collections column columns common computer computing constant data database dataframes datasets developers different distributed downstream drop evaluation execution fault features fill filling filter flag flagging forward framework function functions fundamental github handling import imputation indicator instance key language large last lazy learning library lost luzbetak machine machines memory method methods missing missingness mllib mode model modeling models named nature null numeric objects observation open operations optimizations pages parallel performance plan planning popular powerful predict preprocessing processing programming pyspark python queries query rdds regression relational remove requirements resilient rows scale several single source spark specific specified sql string structure structured subset system table task techniques tolerance tools transformations valid value values various window",
        "url": "/bricks/PySpark-Handling-Missing-Data.html"
    },
    {
        "id": 37,
        "title": "PySpark-Questions-Answers.html",
        "content": "pyspark questions answers action actions algorithms answers apache api apis big catalyst cluster clusters collection columns computation computing concept control count data database databases dataframe dataframes dataset datasets difference distributed driver easier efficient element elements entire evaluation example execution existing external fault features filter flatmap flow function fundamental github high higher inner input interface iterative join joins key large lazy level lineage list logical low luzbetak machines manipulation map memory multiple named new objects open operations optimizer pages pandas parallel parallelism parallelized physical plan plans processing program pyspark python questions rdd rdds relational resilient results rules scale semi single source spark storage structure structured system table tables tasks tolerance transformation transformations two various ways",
        "url": "/bricks/PySpark-Questions-Answers.html"
    },
    {
        "id": 38,
        "title": "databricks-slideshow.html",
        "content": "databricks slideshow full image screen slideshow",
        "url": "/bricks/slideshow/databricks-slideshow.html"
    },
    {
        "id": 39,
        "title": "menu.html",
        "content": "menu aws data databricks devops github kevin luzbetak programming search",
        "url": "/_includes/menu.html"
    },
    {
        "id": 40,
        "title": "footer.html",
        "content": "footer kevin luzbetak",
        "url": "/_includes/footer.html"
    },
    {
        "id": 41,
        "title": "debugging-kubernetes-performance.html",
        "content": "debugging kubernetes performance agent anomalies another api application applications approach autoscaler benchmark bottlenecks c calico capacity cause check cilium cli clues cluster clusters code collection combination communication components conclusion conditions congestion container containers cpu crashes dashboard dashboards debugging degradation dependencies deployments describe description detailed details different disk displays distributed entire environment error errors events exhaustion experience external failed features fio flow flows functions go grafana graphical health high historical horizontal hotspots hpa htop hubble indicators information interactions iops issue issues istio java journalctl jvm key kubectl kubelet kubernetes latencies latency leaks level limits load logs look loss measure memory mesh messages metrics misconfigurations monitor monitoring name native nature network networking node nodes object objects observability oomkilled open operations overview packet performance persistentvolumeclaim persistentvolumeclaims planning plugins pod pods policies policy pprof pressure primary probes problems profiler profiling prometheus pvc py python rates real related reliable request requests resource resources restarts root runtime scaling search service slow smooth snapshot solution solutions source space specific spy ssh stack status steps storage swapping symptoms systematic testing tests throughput time tool tools top traces tracing traffic trends troubleshoot u ui unusually usage use variety vertical visualization vmstat vpa warnings wasted weave web",
        "url": "/devops/debugging-kubernetes-performance.html"
    },
    {
        "id": 42,
        "title": "github.html",
        "content": "github access account actions admin another answer answers applications asked authentication authorization automate automated based best blogs board branch bugs building changes ci cloud code codebase collaboration comment common community conclusion conflicts content contributions contributor contributors control copy core deployment developer developers development directory documentation environments experience feature features files followers forked forks git github global group history interview interviews issue issues job kanban level lines local machine main maintainer management members merge method model modern modifications oauth open organization organizations original others overview owner pages party permissions personal pipelines platform platforms popular powerful practices process production project projects providers pull quality questions range rbac remote repositories repository request requests resources review reviews revisions role roles saml separate services site sites social software source stars static style target tasks team teams testing tests third tool tools tracking users version web websites wide wikis workflow workflows yaml",
        "url": "/devops/github.html"
    },
    {
        "id": 43,
        "title": "general-101.html",
        "content": "general 101 ability abstractions acceptable access accuracy acid action acyclic adheres advantages aggregation airflow alerts algebra algorithms aligns allocation amazon amounts analysis analysts analytical analytics another apache api apis applications atomicity attribute attributes automated automatic automating automation aws azure based basis batch benefits best better big branch branches branching bug build building business capabilities capacity cases category cd central centralized certain chance change changes checks ci clear cloud cloudformation cloudwatch cluster clustering clusters codd code codebase collaboration collaborative collect collection collections column columns commit commits common complex complexity compliance comprehensive computation compute computing concepts conditions configuration configurations conflicting conflicts considerations consistency consistent constraints container containerized continuous control count cross csv current custom cyclic dag dags data database databases databricks datadog dataframe dataframes dataset datasets date dates decision deep delay deleted delta demand denormalized dependencies deploying deployment design developers development df differences different dimension directed distributed dive docker documentation downstream driven duplicated duplication durability edgar efficiency elastic elt encryption end enforced engineering engineers ensure ensures entire entities environment environments error errors etl evaluation event events every example execution expectations expected experiment extract fact failed failure failures fast fault feature features field fields file files finance fixes flat flexibility focus foreign formal formats fosters full functions fundamental gcp general git github gitlab graceful graphs great handling heavy high historical hotfix iac iam idempotency idempotent identifier identifiers identity implement import improved incoming inconsistent indexing infrastructure insights instances integration integrity intelligence intervals intervention isolation issue issues iteration iterative jenkins key keys kubernetes lake lambda language large layer lazy learning level leverage load location logging logic long luigi machine machines main making managed management managing manipulation manner manual marts mechanisms members memory merge merging metadata mlflow mllib model models modern monitor monitoring mr multidimensional multiple mysql new normalized notebook notebooks nothing null numbers numeric object olap oltp one online open operational operations optimization orchestrated orchestration orchestrator orchestrators order others outcome overview pandas parallel parallelism part parts performance pipeline pipelines platform platforms point popular postgresql pr practices predefined prefect previous prices primary process processes processing product production proper protection provisioning purposes pyspark python quality queries query querying range ranges rapid rdds rds reads real record records recovery redundancy reference refers regular relational relations relationships reliability repeatability reporting repositories repository request requests resilient resizable resource resources response result results retries retry reviews row rows rules running sales scalability scalable scale scaling scheduled scheduling schema scientists secure security semi sensitive separation sequence server serverless servers service services session set setup shared sharing simple simplicity single slice small snapshot snowflake source sources spark sparksession specific specified sql stable stages standards star start state states step storage stores strategies stream streaming structure structured subsets system systems table tables target task tasks team teams techniques technologies temporary terraform test testing tests theory thresholds time tolerance tool tools top traceability track tracking transaction transactional transactions transformation transformations transformed travel trend trigger triggering troubleshooting true truth two types unique uniqueness unit updates upstream use user users valid validated validates validation value values various version versions view virtual visualizations volumes warehouse warehouses warehousing way web workflows workload workloads writes",
        "url": "/devops/general-101.html"
    },
    {
        "id": 44,
        "title": "apache-nifi.html",
        "content": "apache nifi ability aggregation analysis apache apis approach audit authentication automation based cases cloud complex compliance csv custom data databases debugging delivery destinations detailed detection developers devices different diverse drag drop efficient encryption enrichment environments extensibility external features filtering finance flow formats formatting fraud friendly ftp government healthcare high http industries ingestion integration interface iot json kafka key lakes large lineage log logs manner mechanisms monitoring nifi non open organizations overview pipelines plugins premises privacy processing processors programming protocols provenance range real routing scalability scenarios seamless services source sources ssl system systems tasks technical telecommunications throughput time tool trails transfer transformation transformations use user users various visual volumes warehouses web wide xml",
        "url": "/devops/apache-nifi.html"
    },
    {
        "id": 45,
        "title": "docker.html",
        "content": "docker access application applications base cloud commands compose consistency container containerization containerized containers control creation dependencies developers development different docker dockerfile ecosystem efficiency environment environments faster features file filesystem host hub image images increased instructions isolated isolation kernel key load local machine machines management multi multiple networking orchestration os points portability previous problem process processes production repository reproducibility scalability scope security series startup swarm system templates testing text tools variables vast version versions virtual vms vulnerabilities",
        "url": "/devops/docker.html"
    },
    {
        "id": 46,
        "title": "apache-airflow.html",
        "content": "apache airflow acyclic airflow amounts analysis apache architecture author based bashoperator celery changes cloud code communication complex configurable connection correct custom dag dags data databases debugging delays dependencies details devops different directed distributed dynamic engineering errors etl execution extensibility external failure features flow generation graph graphs hooks integration integrations interface intervals key kubernetes large learning limits machine managing mechanism mechanisms modular monitor monitoring multiple needs node notifications number open operators orchestrate order overview pipeline pipelines platform platforms plugins points processes programmatically progress python pythonoperator relationships retry rich scalability schedule scheduling science seamless sensors services set small source specific specified sql step systems task tasks technologies triggers troubleshooting types ui user various web workers workflow workflows xcoms",
        "url": "/devops/apache-airflow.html"
    },
    {
        "id": 47,
        "title": "Kubernetes.html",
        "content": "kubernetes access active actual address amount answer answers api apiversion app application applications approach appropriate apps architecture asked automate automated autoscalers autoscaling availability balancing based basic capabilities capacity case cases certificates changes charts claims cloud cluster clusters cncf command communication community complex component components computational computing conclusion conditions configmaps configuration conflicts constraints container containerized containers control controller controllers core count coupled cpu cpus creation custom data databases declarative default definition dependencies deployable deployment deployments desired dev difference different distributed docker downtime easy ecosystem efficiency elk environment environments etcd example execution experience extensibility external f failed features field file foundation fractional functionality given google granular half hand handles healing health healthy helm hierarchy high highest horizontal host hosting hpa http https hub identity image images impact individual information infrastructure ingress inside instance integrations interview interviews ip isolated isolation issues job kernel key kind kube kubectl kubelet kubernetes labels least level levels libraries lifecycle lightweight limit limits load loads logging logs lowest machines main management manager master matchlabels maximum mechanism memory metadata metrics microservices millicores minimal monitoring much multi multiple name namespace namespaces native nature necessary network new nginx node nodes number object observed old one ones open operations operators orchestrate orchestration overview package parts passwords performance persistent physical place plane platform pod pods points policies port portable ports powerful previous private process processes production progress proxy pv pvc questions rate rbac registries reliable replicas replicaset replicasets request requests resource resources restarts reusable revision rich risk role rollback rollbacks rolling rollout rollouts routing running runtime scalability scalable scale scaling scheduler scheduling secrets secure security select selector self sensitive server services set settings share shared simple simplest single smallest snapshots source spec specific specification specifications specified ssl stack staging standards state stateful statefulset statefulsets stateless status storage store strategy sufficient summary system systems tasks template termination three tightly time tls tokens tool tools traditional traffic turn two types typically undo unhealthy unique unit units update updated updates usage use users utilization value varying vcpu version versions virtual volume volumes vulnerabilities way worker workloads yaml",
        "url": "/devops/Kubernetes.html"
    },
    {
        "id": 48,
        "title": "software-delivery.html",
        "content": "software delivery actions another ansible application applications artifact artifactory artifacts aspects assurance automation aws binaries bitbucket building categories centralized chef ci cloud cloudformation code configuration containerization containerized containers continuous control data delivery deploying deployment development different distributed docker elasticsearch elk entire environment environments formats frequent functionality functions git github gitlab grafana hosted industry infrastructure initial integration jenkins key kibana kubernetes legacy lifecycle logging logs logstash management manager metrics modern monitoring multiple nexus open orchestration package performance pipelines platform platforms popular practices process production projects prometheus providers puppet quality recipes reliability reliable repositories repository running scalability scaling server service shipping software source sources stack staging stores subversion svn system task tasks terraform testing tool tools top travis unit universal updates use users various version writing",
        "url": "/devops/software-delivery.html"
    },
    {
        "id": 49,
        "title": "bashrc.html",
        "content": "bashrc archive argument clear code edit else eval exclude exec extension fi file files find first function g grep keyword l least linux local max mkdir one open os printf py python replace rnw search second spy text tpy two xargs",
        "url": "/devops/bashrc.html"
    },
    {
        "id": 50,
        "title": "Python-Search-Algorithms.html",
        "content": "python search algorithms algorithm another arr array base binary case containing current def element elements elif first function half halves index intersection iteration length list lists merge mid middle output pivot process quick result return right search second single sort target two x",
        "url": "/programming/Python-Search-Algorithms.html"
    },
    {
        "id": 51,
        "title": "Python-String-Algorithms.html",
        "content": "python string algorithms actual aeiouaeiou algorithm algorithms anagram anagrams analysis another args argument array base binary boolean buzz cases char character characters check checking common comparison correction corresponding cost def deletion deletions detection distance distances dna dp dynamic edits element elements elif equal error example false fill first fizzbuzz function hamming import indices input insertion insertions int integer j karolin language last lcs length levenshtein list longest maximum measure metric minimum n natural non none np number numpy one operation order original output pair palindrome positions processing programming python repeated representation result return returns reverse row second sequence sequences similarity single size sort sorted spell str string strings subsequence substitution substitutions table true two value values versions vowels world x",
        "url": "/programming/Python-String-Algorithms.html"
    },
    {
        "id": 52,
        "title": "Python-Coding-Exercise-Algorithms.html",
        "content": "python coding exercise algorithms algorithms bool char character coding complement def duplicates enumerate example exercise first int intersection j largest list lists merge merged non none num number nums olleh output palindrome problem python range repeated return sorted str string sum true two usage vowels world",
        "url": "/programming/Python-Coding-Exercise-Algorithms.html"
    },
    {
        "id": 53,
        "title": "101.html",
        "content": "101 actual aeiouaeiou algorithm algorithms anagram anagrams analysis another args argument arr array base binary boolean buzz case cases char character characters check checking common comparison complement containing correction corresponding cost current def deletion deletions detection distance distances dna dp duplicates dynamic edits element elements elif equal error example false fibonacci fill first fizzbuzz function half halves hamming import index indices input insertion insertions int integer intersection iteration j karolin language last lcs length levenshtein list lists longest loop maximum measure merge metric mid middle minimum n natural nested non none np num number numbers numpy nums one operation order original output pair palindrome pivot positions problem process processing programming python quick recursive remaining repeated representation result return returns reverse right row search second sequence sequences series similarity single size sort sorted specific spell str string strings subsequence substitution substitutions sum table target true two value values versions vowels world x",
        "url": "/programming/101.html"
    },
    {
        "id": 54,
        "title": "Python-Programming-Language.html",
        "content": "python programming language access algorithms analyzing anonymous arguments async asynchronous asyncio attributes behavior break cases classes closures code collection complexity comprehensions concurrency conditional context control counting cprofile csv custom data debugging decorators def default defining dependencies designing development dictionaries differences different django dunder efficient encapsulation environments error exceptions explicitness expressions file files flask flexible flow fly frameworks functions garbage generator generators gil guide handling higher idiomatic immutable implications importing inheritance init inline iter iterators itertools json key lambda language libraries library list lists loops management managers managing math matplotlib memory methods mock mocking modules multiprocessing multithreading mutable numpy object objects optimization order oriented packages pandas parameters pdb pep performance polymorphism popular practices principles private profiling program programming properties public python pythonic readability readable reading reference requests results scikit sequence sets simplicity special standard statements str structures style sys systems test testing text time timeit tools tuples types understand understanding unit use values venv virtual ways web writing yield zen",
        "url": "/programming/Python-Programming-Language.html"
    },
    {
        "id": 55,
        "title": "mysql-lag-function.html",
        "content": "mysql lag function analysis average avg chronological clause column curdate current daily data date dates day days decimal difference differences explanation filtering four function increase increases interval lag last mysql null order outer overview places previous price purpose query result round row rows select sequential series sql time valid value values window",
        "url": "/programming/mysql-lag-function.html"
    },
    {
        "id": 56,
        "title": "Python-Function-OOP-Data-Structure.html",
        "content": "python function oop data structure age alice animal anonymous another argument array async asynchronous asyncio attribute attributeerror author await basic bob book buddy c call cat class classes closures code collection common concurrency csv data decorators def defining dictionaries dictionary different dog dunder dynamic element elements encapsulation example expression file func function functions generator generators george header headers hi higher immutable import individual inheritance init item iterator iterators key keys lambda line list lists main memory meow methods msg multiple multiplier multiprocessing multithreading name next numbers object objects order oriented orwell output pair person polymorphism print private process processes program programming python r range reader reading return row rows sample self separate sequence set sets simple single spaces square str structures target thread threading threads tuple tuples unique unordered value woof wrapper x yield yields",
        "url": "/programming/Python-Function-OOP-Data-Structure.html"
    },
    {
        "id": 57,
        "title": "Sudoku-Board-Verification.html",
        "content": "sudoku board verification args board bool checks col column columns completed conditions example expected false function given grid grids import inner int list lists logic matrix module name numbers output parameters pprint pretty prettyprinter prints provided puzzle python result return returns row rows rules script specified standard start steps sub sudoku sum sums total true value verification verifies whether window",
        "url": "/programming/Sudoku-Board-Verification.html"
    },
    {
        "id": 58,
        "title": "Python-Algorithms.html",
        "content": "python algorithms algorithm argument array complement def element elements fibonacci function indices integer j list lists loop merge n nested number output recursive remaining result series sorted sum target two value values",
        "url": "/programming/Python-Algorithms.html"
    },
    {
        "id": 59,
        "title": "algorithms2.html",
        "content": "algorithms2 args character collections comparison convert counter def deletions distance dp dynamic first hamming import insertions int j levenshtein libraries math n necessary number numpy programming return returns second string strings substitutions two",
        "url": "/programming/algorithms2.html"
    },
    {
        "id": 60,
        "title": "algorithms.html",
        "content": "algorithms algorithm algorithms anagram anagrams another applications argument arr array article backtracker backtracking base bellman binary bits bitwise boolean breadth bubble buzz case characters check code coding coins combinatorics common complement computational computer conclusion containing cryptography current data def desired different dijkstra distance dp dynamic edges element elements elif engineering examples explanation factorial fibonacci first five fizzbuzz following ford formula function gcd given graph half halves hamming hash implement important index indices information insertion integer integers interviews iteration j key knapsack last length levenshtein linear list longest loop matrices matrix maximum merge mid middle multiples multiplication n negative nested networks neural nth number numbers operations optimization order original pair palindrome parts passwords paths pivot popular possibilities powerful print problem problems process programming python queens quick range real recursion recursive regression remaining representation result return reverse row salesman science search second selection series set shortest single size smaller solution sort sorted sorting specific stairs steps str string strings subproblem subproblems subsequence sudoku sum tables target tasks term three tools traveling trees two types user value values various ways weight wide world x",
        "url": "/programming/algorithms.html"
    },
    {
        "id": 61,
        "title": "Fibonacci-Generator.html",
        "content": "fibonacci generator b current def example execution fibonacci first function generator github infinite iteration loop luzbetak next numbers pages sequence state statement sum two usage value values yield",
        "url": "/programming/Fibonacci-Generator.html"
    },
    {
        "id": 62,
        "title": "Gmail-Email-Fetch.html",
        "content": "gmail email fetch access account analysis another api archival authentication breakdown build complete content credentials creds data date def define description details email emails example f fetch fetched file formatting future gmail google id import important installedappflow internal json key last local login messages msg new none oauth os output payload process prompt purposes python read readable retrieval runs saving scope scopes script service simple snippet system user uses valid w way",
        "url": "/faiss/Gmail-Email-Fetch.html"
    },
    {
        "id": 63,
        "title": "Indexing-FAISS-OpenAI-Embeddings.html",
        "content": "indexing faiss openai embeddings advanced boilerplate cases class cleaned code conclusion content convert converts create dash dashes data database date datetime define description doc document documents e efficient elements email emails embeddings entities explanation extra faiss fast fields file following function future html id ignorecase import index jq json jsondecodeerror jsonloader learning loads machine message metadata models object objects one openai openaiembeddings parse processing provided python relevant remove replace retrieval schema script search searches searching sequences set setup similarity spaces store stores tasks text timestamp types unknown unnecessary unwanted urls use various vector",
        "url": "/faiss/Indexing-FAISS-OpenAI-Embeddings.html"
    },
    {
        "id": 64,
        "title": "RetrievalQA-FAISS-with-OpenAI-GPT-4.html",
        "content": "retrievalqa faiss with openai gpt 4 ability answer answering answers anything api applications architecture base breakdown chain chatbots chatopenai code conclusion construction content context conversational data databases description deserialization disk docs document documents e embeddings empty end ensure environment error errors exception exit explanation faiss fast filenotfounderror following framework functionality general goodbye gpt handling import imports index indexed information key knowledge language llm llms loop manual manually model models natural openai openaiembeddings output parameters powerful precise purpose python qa query question questions relevant responses result results retrieval retrievalqa retrieved retriever retrievers safe scenarios scope script setting setup simple snippets specialized step stores system systems text type unsupported updated user users valueerror variable various vector yet",
        "url": "/faiss/RetrievalQA-FAISS-with-OpenAI-GPT-4.html"
    },
    {
        "id": 65,
        "title": "Amazon-RDS.html",
        "content": "amazon rds advanced amazon analytical api application applications aurora automated automates availability aws az backend backup backups capabilities cases choice cli clicks cloud cloudwatch common compute console consuming cost costs credentials data database databases demand demands deployments development dms drivers easy effective encryption engine engines enterprise environments excellent failover features flexible grade hardware high import ingestion instance instances integration isolation key kms layers load managed management mariadb microsoft migration mobile models monitoring multi multiple mysql native network operation oracle organizations patching patterns performance point popular postgresql pricing provisioning rds recovery relational reliable replicas reserved resources rest scalability scale scaling security server service services setup several smaller snapshots solution sql staging standard storage tasks testing time tools transit usage use vpc warehouses web zone",
        "url": "/aws/Amazon-RDS.html"
    },
    {
        "id": 66,
        "title": "AWS-CloudWatch.html",
        "content": "aws cloudwatch access actions activity alarms alerts amazon anomalies application applications automate automated automation aws balancers behavior build cases certain changes cloud cloudwatch collect collection common comprehensive conditions configure cpu create custom dashboards data databases defined ecosystem efficiency entire environment environments errors essential eventbridge events example failure features filters functions gain health immediate infrastructure insights instances interface issues key lambda learning load log logs machine memory metric metrics monitor monitoring notifications observability operational operations part patterns performance premises problems rds real related reliability resource resources response responses security service services single specific thresholds time tool unauthorized unusual usage use utilization view visibility visual web workflow",
        "url": "/aws/AWS-CloudWatch.html"
    },
    {
        "id": 67,
        "title": "Amazon-S3.html",
        "content": "amazon s3 access accessed amazon amount amounts analysis analytics api apis applications archival archive archiving athena automated availability aws backup backups big bucket buckets cases cdn centers class classes cloud cloudfront common compliance computing content controls cornerstone cost costs custom data datasets deep delivery different disaster dispersed distribution diverse documents durability effectiveness emr encryption features fine flexibility frequently geographically glacier grained high hosting hours ia iam identity images infrequent infrequently integration internet key lakes lambda languages large layers lifecycle long lower lowest management many minutes multiple needs number object objects one option options patterns policies pricing processing programming range rapid reasons recovery redshift regions reliability replication requests rest restful retrieval scalability scalable scale sdks security serverless service services simple single sources specific spectrum sql standard static storage storing term tiers times tools transfer transit transition two unlimited usage use users variety various versioning versions videos virtually web wide zone",
        "url": "/aws/Amazon-S3.html"
    },
    {
        "id": 68,
        "title": "ETL-Pipeline-AWS.html",
        "content": "etl pipeline aws acceleration access activity alarms amazon analysis analytical another apache api apis archival auditing auto automation aws big buckets catalog cleaned cloudwatch complex compliance config create data database databases datasets define dynamodb emr ensure etl events example external extract failures flow format frameworks fully functions glue hadoop iam identity ingestion inspector internal issues job jobs key kinesis kms lake lambda large load loading log logging logs managed management mapreduce metadata monitor monitoring needs nosql option orchestration party performance pipeline policies processing purposes queries raw rds real redshift regulations relational reporting resources rest roles scale scaling schedules schema security sequence service services simple sources spark specific speed step storage store streams third time track transfer transform transformation transformations transit trigger use various warehouse workflow",
        "url": "/aws/ETL-Pipeline-AWS.html"
    },
    {
        "id": 69,
        "title": "AWS-EMR.html",
        "content": "aws emr access advanced algorithms amazon amounts analysis analytics apache aws batch big businesses cases cloud cluster common complex configuration control cost costs data datasets dynamodb ecosystem effective emr encryption environment etl example features flink framework frameworks hadoop hbase hive iam infrastructure instances integration isolation job jobs key languages large layers learning machine managed mapreduce mllib multiple necessary needs network options others pig platform presto pricing processed processing provisioning python querying raw real redshift resources rest results running scala scalability scale security service services spark spot sql storage store streaming tasks termination time transformations transit tuning underlying use vast warehousing workflow",
        "url": "/aws/AWS-EMR.html"
    },
    {
        "id": 70,
        "title": "AWS-Glue-Workflow.html",
        "content": "aws glue workflow amazon analytics arrival automation aws bucket cases catalog cloudwatch common completion complex comprehensive conditional configuration configure connecting console coordinate correct crawler crawlers custom data define dependencies destinations different editor error etl even events example execution failure feature features flexibility flow flowchart glue ingestion integrated integration interface issues job jobs key lake logging logic management metadata monitor monitoring multiple necessary orchestration order parallel part path paths pipelines predefined previous processes processing progress real redshift scale scheduled schedules sequence solution sources status success tasks time transformations trigger troubleshoot upstream use various visual warehouse warehousing workflow workflows",
        "url": "/aws/AWS-Glue-Workflow.html"
    },
    {
        "id": 71,
        "title": "AWS-Kinesis-Data-Streams.html",
        "content": "aws kinesis data streams amazon analytics applications aws cases centralized common data distributed etl event features fly full ingestion insights integration interactions key kinesis lambda large log logs metrics monitoring name personalization phase pipeline processing real redshift scalability service services sources streaming streams time tracking use user various volume",
        "url": "/aws/AWS-Kinesis-Data-Streams.html"
    },
    {
        "id": 72,
        "title": "AWS-Step-Functions.html",
        "content": "aws step functions access amazon another api application approvals automate automation aws batch business call common completion complex console coordination data decision defined definition deployment design different distributed dynamodb easy ecs editor end environment error errors etl evaluation example executes execution external extraction failed fault features final flowchart function functions glue handling human iam infrastructure input integration interface jobs json key lambda language learning loading long machine making management microservices model monitoring multiple orchestrate orchestration output path pipelines policies preparation process processes processing redshift reliability reliable roles running scalability sdk security serverless servers service services start state states step steps storage systems task tasks training transformation transitions use validation various visual workflow workflows",
        "url": "/aws/AWS-Step-Functions.html"
    },
    {
        "id": 73,
        "title": "AWS.html",
        "content": "aws access accurate ad amazon analytics assets athena auditability automatic aws backbone cases catalog cataloged centralized changes common component configuration core crawlers data databases date define different discovery emr environment etl evolution example fast features flow glue governance history hoc iam identity infer information job jobs key lake lakes landscape lineage manage management manual metadata monitor partitions pipelines place policies powerful process processes queries query redshift reference repository schema schemas services single sources spectrum storage stores strategy structures tables time tool track tracking transformations transforming transparency updates use users various versioning warehouse warehouses workflow",
        "url": "/aws/AWS.html"
    },
    {
        "id": 74,
        "title": "AWS-Config-Inspector.html",
        "content": "aws config inspector account action actionable actions adherence alerts analysis applications approach assessment assessments audit auditing automate automated automatically aws basis best better breaches capabilities cases change changes checks ci clear cloudtrail common compliance compliant config configuration configurations configure continuous controls create current define defined demand dependencies deployments desired detailed deviations devops disaster dss environment evaluation example execute execution exposed external features findings governance historical iam identified impacts improvement incident incidents industry insecure inspector integration internal inventory investigate issues key lambda management misconfigurations monitor monitoring non notifications ongoing operational organizational part patches pci pipeline planning policies ports posture potential powerful practices predefined process recommendations recommended recorded recovery regular regulations regulatory relationships remediate remediation report reporting reports requirements resource resources response risks rules run schedule scheduled secure security service services set sns software standards state status targets templates thorough time track troubleshooting unpatched use view vulnerabilities vulnerability way workflow",
        "url": "/aws/AWS-Config-Inspector.html"
    },
    {
        "id": 75,
        "title": "KMS-Key-Management-Service.html",
        "content": "kms key management service access activities additional api application applications approach audit auditing authenticity automatic aws behalf best cases centralized cli cloud cloudtrail cmk code common communications compliance configuration consistent console control created cryptographic custom customer customers data define deletion digital ebs encrypt encryption environment example feature features granular hardware highly hsms iam industry information integrated integration integrity key keys kms lambda layer level lifecycle managed management managing master minimal modules ongoing operations others permissions policies practices protection providers range rds regulations regulatory repository requirements rest rotation saas sdk security sensitive service services signing single solution specific specifying standards store transit unified usage use users various wide workflow",
        "url": "/aws/KMS-Key-Management-Service.html"
    },
    {
        "id": 76,
        "title": "Lambda-Serverless-Computing.html",
        "content": "lambda serverless computing access actions ai aliases amazon api apis application applications assistants automated automatically automation availability aws backend behavior c cases changes charges chatbots code common complex comprehend compute computing cost create custom data database databases design development devices different driven dynamodb effective efficiency environment environments etl even event events executes execution external extract features file files fine flexibility function functions gateway generating grained handle high http iam identity images incoming information infrastructure input instances integration intervention invocations iot java key lakes lambda languages levels log logic management managing manual many message messages milliseconds multiple new notifications number orchestration overhead performance permissions persistent power pricing process processing production programming provisioning python queues range rds real records rekognition requests resizing resource resources response role roles ruby runtime scalability scenarios secure server serverless servers service services several shifts sns sources specific sqs staging state stateless storage streams support supports system tasks thumbnails time traffic transform transformation trigger triggers underlying usage use user variables variety various varying versions videos voice web wide workflows",
        "url": "/aws/Lambda-Serverless-Computing.html"
    },
    {
        "id": 77,
        "title": "Auto-Scaling-EC2-EMR.html",
        "content": "auto scaling ec2 emr action activities amazon amount application applications auto automated automatically availability aws balancing batch big build capacity cases changes checks ci cloudwatch cluster clusters common complexity configure consistent continuous cost costs cpu current custom data day demand deployment desired devops disaster dynamic effective effectiveness efficiency elastic elb emr environment environments events example failed features flexible group groups health high instances integration intensive job jobs key levels load mapreduce memory metrics monitor necessary new nodes number ones operations optimal optimization optimize patterns performance pipelines policies powerful predictable processes processing quick real recovery resource resources response review right scale scaling scheduled schedules seamless service services set size solution specific target test time timely times tracking traffic unhealthy unpredictable usage use utilization way web week workflow workload workloads",
        "url": "/aws/Auto-Scaling-EC2-EMR.html"
    },
    {
        "id": 78,
        "title": "AWS-CloudWatch-Events.html",
        "content": "aws cloudwatch events action actions adjustments alerting alternate api application applications architectures auditing audits automate automated automation aws backups building cases change changes checks cloud cloudwatch common complex compliance component components conditions corrective corresponding criteria cron custom data detailed driven ecosystem efficiency environment error errors event events example execution failed flexible function functions handle handling health infrastructure instance instances intervals key lambda load log logging logic logs mechanisms monitor monitoring near needs notification operations performance periodic powerful processing real regular relevant reliability resources response responses retry review robust rotation rule scheduled scripts security service services sns source specific state step stream system target tasks time trigger triggers troubleshooting unnecessary use way workflow workflows",
        "url": "/aws/AWS-CloudWatch-Events.html"
    },
    {
        "id": 79,
        "title": "AWS-Glue-ETL-Service.html",
        "content": "aws glue etl service actual amazon analysis analytics another apache argument aurora automatically aws basic bucket cases catalog cleaning code common completion crawlers custom data database databases definitions desired different discovery distributed either enriching environment etl example extract f features field filtering format fully getresolvedoptions glue gluecontext hood import infrastructure initialization input integrated integration interface intervals intervention job jobs joins json key kinesis lakes lambda less load location managed manual mapping metadata name object optimal output part paths performance preparation process processing provisions python querying range rds real records redshift relational required resources result results sc scala scalability scale scales scenarios schema script seamless serverless service services simple sources spark sparkcontext specific step storage store stores studio sys table target time transformation transformations transformed transforming types usage use variety various visual warehouses web wide work workflow workload writing",
        "url": "/aws/AWS-Glue-ETL-Service.html"
    },
    {
        "id": 80,
        "title": "S3-Transfer-Acceleration.html",
        "content": "s3 transfer acceleration accelerated acceleration access additional amazon amounts applications assets aws backups benefits bucket budget business case cases changes clients closest cloudfront cloudwatch common console content control cost costs critical cross data datasets deadlines desired distance distances distant distributed edge effective enabling endpoint example existing expected factor faster feature features file files geographically global globally iam identity improved infrastructure key large latency location locations long management media metrics monitor nearest need network new operations optimized paths performance processing reach region regions reliability requirements review scale scenarios security sensitive settings solution speed speeds ssl standard streaming time transfer transfers transit upload uploads use users video workflow workflows world",
        "url": "/aws/S3-Transfer-Acceleration.html"
    },
    {
        "id": 81,
        "title": "IAM-Identity-Access-Management.html",
        "content": "iam identity access management access account actions active activities added addition additional another api application applications attach audit authentication authorized aws best calls cases cloud cloudtrail common compliance compliant consultants control controls create credentials critical cross custom define directory enhance environment exactly example external factor feature federation fine form foundational google grained granular group groups iam identity individual json lambda least limited long management mfa microsoft monitor multi needs one organization parties password patterns permissions policies powerful practices principle privilege protection provider providers regulatory requirements resources role roles saml second secure security service services specific step strict stronger temporary term third tool unauthorized use user users web workflow",
        "url": "/aws/IAM-Identity-Access-Management.html"
    },
    {
        "id": 82,
        "title": "AWS-Glue-Data-Catalog.html",
        "content": "aws glue data catalog access accurate ad amazon analytics assets athena auditability automatic aws backbone cases catalog cataloged centralized changes common component configuration core crawlers data databases date define different discovery emr environment etl evolution example fast features flow glue governance history hoc iam identity infer information job jobs key lake lakes landscape lineage manage management manual metadata monitor partitions pipelines place policies powerful process processes queries query redshift reference repository schema schemas services single sources spectrum storage stores strategy structures tables time tool track tracking transformations transforming transparency updates use users various versioning warehouse warehouses workflow",
        "url": "/aws/AWS-Glue-Data-Catalog.html"
    },
    {
        "id": 83,
        "title": "AWS-CloudTrail.html",
        "content": "aws cloudtrail access account actions activate activity alarms amazon analysis analyze anomalies api athena audit auditing automated aws bucket call calls cases change changes cloud cloudtrail cloudwatch command common complete compliance comprehensive configurations configure conjunction console dashboards data detailed detecting durable environment essential event events example external files forensic governance historical history incident industry infrastructure insights internal investigate issues key line log logging logs long management monitor monitoring notifications operational party patterns potential problem record recording regions regulations relevant requirements resources responses retention risk roles sdks secure security sequence service services specific standards storage store term third threats time tools track trail troubleshooting unauthorized unusual use user users visibility workflow",
        "url": "/aws/AWS-CloudTrail.html"
    },
    {
        "id": 84,
        "title": "AWS-Redshift.html",
        "content": "aws redshift access amazon analysis analytical analytics aws bi big businesses central cloud cluster clusters columnar commands complex compression control copy cost costs data databases datasets decision demand destination destinations driven dynamodb ecosystem effective emr encryption etl example export fast fine fully gb glue grained iam ideal ingestion insights instances integration isolation jobs language large load looker making multi network new node organizations parallel performance petabyte petabytes pricing processed processing purposes queries query quicksight real redshift reporting reports reserved resources rest results run scale security semi service services single solution sources sql standard storage structured tableau time tools transformation transit use users various visualizations vpc warehouse warehousing workflow workload workloads",
        "url": "/aws/AWS-Redshift.html"
    },
    {
        "id": 85,
        "title": "Creating-Data-Lake-with-AWS-Lake-Formation.html",
        "content": "creating data lake with aws lake formation ability access actual administrators amazon analysts analytics analyze apache appropriate athena audit authorized aws bucket catalog central centralized certain classification cloudtrail cloudwatch column compliance compression conclusion console control crawlers create creation data database databases datasync define detailed different direct efficient emr encryption enforce extraction features file fine folders format formation formats framework frameworks glue governance governed grained granular grouping guide hadoop iam identity indexing ingest ingestion integration jobs key kms lake lakes large learning level location locations logical machine management metadata ml monitor multiple names optimize orc parquet partitioning partitions patterns performance permissions policies policy portions previous query querying redshift register registered repository required rest roles row sagemaker scale schema schemas secure security sensitive service services sources spark specific spectrum sql step steps stewards storage strategies structure subsets table tables techniques transit types unified uploads usage use users well",
        "url": "/aws/Creating-Data-Lake-with-AWS-Lake-Formation.html"
    },
    {
        "id": 86,
        "title": "Apache-Parquet.html",
        "content": "apache parquet access amount analytic analytical analytics apache architectures aws azure based benefits big bigquery cases changes cloud columnar columns common compatibility compression costs data datasets dictionary distributed easy efficient encoding engines environments etl evolution existing expenses fast faster features file files format frameworks google hadoop hive impala improved integration key lakes large length lower many massive modern multiple necessary new olap operations optimized parallel parallelism parquet parts performance pipelines platforms processing queries query read redshift reduced retrieval rle scalability scale schema services size spark specific splitting storage stored stores support synapse system systems techniques time use warehousing wide workloads",
        "url": "/data/Apache-Parquet.html"
    },
    {
        "id": 87,
        "title": "Apache-Iceberg.html",
        "content": "apache iceberg access acid analytics apache cases changes cloud columns complex data dataset datasets deletes durable dynamic efficiency enables entire evolution existing features flexible framework frequent hidden historical iceberg key lakes large management manual metadata model models modern need needs object operations partition partitioning partitions petabyte previous queries query reliable removing scale schema storage supports time transactions travel updates upserts use users versions",
        "url": "/data/Apache-Iceberg.html"
    },
    {
        "id": 88,
        "title": "Graph-Databases-ArgoDB-Neo4j.html",
        "content": "graph databases argodb neo4j acid alice analysis analytics apis arangodb argodb argodbexample billions breakdown case cases class code complex compliance concept connection consistency create cypher data database databases datasets db deep detection different distributed document driver edges efficient ensures example excels explanation fast features fraud friend friends function given graph graphdatabase handles high import insights integrates integration key language languages large massive match matching method methods model multi name networks new node nodes password pattern people performance person platforms popular processing python queries query querying rapid recommendation record related relation relationship relationships reliability result scalability scale session sessions setup social specialized storage syntax systems transactions traversal two usage use user value way workloads",
        "url": "/data/Graph-Databases-ArgoDB-Neo4j.html"
    },
    {
        "id": 89,
        "title": "GraphQL.html",
        "content": "graphql access accessing accounts acquisition ad administrators ads advertisers amount analytics api apis applications apps audiences authentication automated based benefits budgets business businesses campaigns changes chatbots clients comments communication complex content control conversational creator credentials customer data description developers different direct ecosystem efficiency efficient email end endpoint endpoints engagement environments event events exactly facebook features fetching fields flexibility flexible friends front functionality graph graphql group groups info information insights instagram interactions interfaces key language likes list lot managing marketers marketing media members messages messaging messenger metrics microservices multiple name names network notifications one page pages part party performance permissions photos platform platforms play posts precise predictability primary professional profile profiles programmatic queries query reach real redundant relationships replies reports request requests required response rest schema server service sets single specific structure structures subscriptions support teams third time title titles transfer types usage user users validating videos way websites whatsapp",
        "url": "/data/GraphQL.html"
    },
    {
        "id": 90,
        "title": "Large-Scale-Data-Ingestion2.html",
        "content": "large scale data ingestion2 acid additional advanced amazon amounts analytics apache application applications automation aws azure based batch beam big capabilities cloud cluster compliance computation confluent connectors data databricks dataflow delta distributed end engineering enterprise event events extension features flink flow framework fully google grade high hubs ingestion iot kafka key kinesis lake large latency logs low managed management manner massive message messaging millions movement multi multiple nifi parallel pipelines platform powerful processing pulsar ready real registry role scalability scale schema second security service sources spark storm stream streaming streams structured system systems telemetry tenancy throughput time tool tools transformation variety wide",
        "url": "/data/Large-Scale-Data-Ingestion2.html"
    },
    {
        "id": 91,
        "title": "Kafka-Producer-Consumer.html",
        "content": "kafka producer consumer apache brokers consumer description earliest format import initializes json kafka kafkaconsumer kafkaproducer lambda list message messages offset print producer specified topic x",
        "url": "/data/Kafka-Producer-Consumer.html"
    },
    {
        "id": 92,
        "title": "sql-statements.html",
        "content": "sql statements add address addresses alias alter altering alumni autoincrement average avg brown cartesian case check clause clauses column columns combine combines common conditional conditions count create cross cte customers data date default delete department departments departmenttotals desc description different distinct drop dropping duplicate duplicates e either else email emails employee employees end equality example examples existence existing exists explanation expression filter first following full group groups hierarchical high index inner insert integer ip jane john join key keywords languages least left limit limits list lists location main manager managers match matched medium michael minimum name names new none null number one order outer output pagination part partition price prices primary product products programming queries query ranges record records related removes rename result results retrieval retrieve returns right row rows salary sales sample second select self set sets side smith snowflake specified speed sql standard statement statements structure student students subquery sum table tables temporary timestamp top total truncate two types union unique update value values varchar view virtual",
        "url": "/data/sql-statements.html"
    },
    {
        "id": 93,
        "title": "Data-Mesh-Decentralized-Architecture.html",
        "content": "data mesh decentralized architecture access accessibility accuracy additional agility analysis approach architecture architectures aspect authorized autonomous autonomy balance benefits best better big bottlenecks building business capabilities capability central centralization centralized challenge changes clear cloud collaboration complexities complexity compliance computing consistent consumers coordination core data datasets decentralization decentralized design differences domain domains driven federated flexibility global governance high idea improved increased independent infrastructure key large limitations location main management managing mesh model models needs often organization organizations oriented ownership pipelines platform policies principles processes processing product products quality recent reliability repository requests requirements resources response responsibilities rigid scalability scales scaling security self service several skillset solutions specific standards strong system systems team teams technical technologies tools traditional traffic training unit units usability users volumes",
        "url": "/data/Data-Mesh-Decentralized-Architecture.html"
    },
    {
        "id": 94,
        "title": "Apache-Hudi.html",
        "content": "apache hudi acid analytics apache architectures background batch big capabilities cases changed compaction compression conclusion cost data datasets deletes effective efficient environments features file footprint framework fresh gap guarantees hadoop historical hudi incremental incrementals indexes indexing ingestion inserts key lake lakes large latency low management modern older open overall performance pipelines previous processing queries query querying real scalable scale scenarios sizes source storage support systems techniques time top traditional transaction transactional transactions travel updates upserts use users versions",
        "url": "/data/Apache-Hudi.html"
    },
    {
        "id": 95,
        "title": "sql-create-view.html",
        "content": "sql create view conditions create department departments e employee employees group joins names query salaries select simple sql statement sum total view",
        "url": "/data/sql-create-view.html"
    },
    {
        "id": 96,
        "title": "Query-Performance.html",
        "content": "query performance access advanced age aggregations amount analysis analyze automatic aws batch benefit best better bigquery bottlenecks caching city clauses cloud clustering clusters column columns complex compute conditions consumption cost costs count create customers data database databases dataset datasets date decimal decisions denormalization desc disk distribution efficiency efficient employees executed execution explain explicit fast faster filtering frequently full group grouped hash help importance improvement index indexes indexing inefficiencies inserts int join joins key keys large leverage limit limiting maintenance materialized memory merge multiple name names need nodes number offset olap operational optimization optimized optimizer order partitioned partitioning performance plan practices precomputed price products proper queries query range redshift reducing regular resource result results rows run salaries sales scalability scalable scan scans segments select single size smaller snowflake space specific sql statistics stores suboptimal subset systems table tables tasks techniques times tools types update updates use using utilize vacuum view views virtual warehouses well writes",
        "url": "/data/Query-Performance.html"
    },
    {
        "id": 97,
        "title": "sql_overview.html",
        "content": "sql overview ability access additional alter analysis analytical category changes characteristics columns command commands common commonly complex conditionals control create cube current data database databases dcl ddl delete deleting dml dql drop elements existing extensions functionality functions grant group index indexes insert inserting integrity isolation language level loops managing manipulating modifies new object objects one oracle part point privileges procedural query records relational removes retrieval roles rollup rows schemas select server set significance specific specifies sql structure structured structures table tables tcl transaction transactions truncate types update used users variants window",
        "url": "/data/sql_overview.html"
    },
    {
        "id": 98,
        "title": "Collibra-Data-Quality.html",
        "content": "collibra data quality acceptable accuracy actionable allows analytics anomalies automated aws azure benefits broken business capabilities catalog checks cloud collaboration collibra completeness compliance conducts consistency continuous creation custom dashboard dashboards data decision depth detailed detects different discovery duplicates efforts enables enhance enriched enterprise errors experience failed features finance glance governance health healthcare high impact improved improvement inaccuracies industries insights integrates integration interactive issues key large learning lineage machine making management metrics mitigates models monitoring multi needs observability operational operations organizations overall owners performance pipelines platform platforms poor potential predefined proactive processes profiling progress quality real reduced regulatory remediation reporting reports requirements retail risks rules scalable standardization standards stewards stewardship support surfaces systems teams telecommunications thresholds time timeliness tool transformation trust trustworthiness types user users uses validation visibility volumes workflows",
        "url": "/data/Collibra-Data-Quality.html"
    },
    {
        "id": 99,
        "title": "Apache-Kafka.html",
        "content": "apache kafka aggregation application architecture availability brokers cases cluster communication compaction confluent connect consumers data decoupled delivery different easy ecosystem external fault hardware high immutable integration integrations kafka key large latency latest library load log long low messages minimal multiple options partition partitions parts policies processing producers range real records regist requirements retention scalability scaling schema semantics sequence servers sinks sources storage stream streams systems throughput time tolerance tools topics use value volumes wide",
        "url": "/data/Apache-Kafka.html"
    },
    {
        "id": 100,
        "title": "Snowflake-Architecture.html",
        "content": "snowflake architecture allows analysis approach architecture auditing auto avro aws azure based bottom centralized cloning cloud clusters compressed compute consistency context copy cost data databases days denormalized departments dimensional edw efficiency efficient elasticity enterprise environments fast flexibility flexible format gcp high historical ideal individual inmon integration json kimball large layer marts modeling modern native normalized optimizations organization organizations parquet performance platform premise processing providers queries query querying quick recovery reporting resources retention scalability scalable scale scaling schemas semi snowflake sources space star storage stores structure structured supports tables time top travel various virtual volumes warehouse warehouses warehousing wins workloads zero",
        "url": "/data/Snowflake-Architecture.html"
    }
]