[
    {
        "id": 1,
        "title": "TF-IDF.html",
        "content": "tf idf another breakdown column content corpus data decimals distinguishing doc document documents entire example feature frequency high higher highest idf import importance initialize inverse learning limit low lower machine many matrix model multiple names particular practice prettytable range ranking result row rows sample score scores specific summary table term terms text tf tfidfvectorizer theory uniqueness upper value values vectorizer word words",
        "url": "/TF-IDF.html"
    },
    {
        "id": 2,
        "title": "Retrieval-Augmented-Generation.html",
        "content": "retrieval augmented generation accurate algorithm augment augmented base bert chatbot components conn contextual cur database datasets dimensional document documents embeddings extension external following generate generated generation generator gpt high import indexing information informed insert key knowledge large limit management model models multiple necessary nodes optimization order parallel performance pgvector pgvectorscale postgresql primary process python queries query question rag references relevant repositories response responses retrieval retrieve retrieved scale searches select serial similarity solution step storage store systems table tasks text transformers tutorial user values vector vectors",
        "url": "/Retrieval-Augmented-Generation.html"
    },
    {
        "id": 3,
        "title": "Tensors-Machine-Learning.html",
        "content": "tensors machine learning access additional array average building channels code color column complex computation computations data deep depth dimensional dimensions efficient element elements essence even example excellent foundation frameworks function functionality functions fundamental generalization gpus height high images import index indexing key language learning library list machine matrices matrix mean models multi multidimensional natural ndarrays np number numbers numerical numpy operation operations output points powerful python pytorch row scalar simple single solid spaces specific structure sum support syntax table tensor tensorflow tensors time total training us value values vector vectors videos width words",
        "url": "/Tensors-Machine-Learning.html"
    },
    {
        "id": 4,
        "title": "Random-Forest-Classifier-Model.html",
        "content": "random forest classifier model account accuracy address approach authentication automation balance billing card case categories category charge classification classifier classifieri clf code collection credentials cryptocurrency customer damaged data date decision delivery depth details device df dictionary different discount either email factor feature features final forest generalization generator gift history hyperparameters idf import incoming individual information input internal invoice item labels leaf length lists login manual maximum method methods minimum missing model nearest new node notifications number numerical options order output outstanding pandas parameter password payment pd pin plan policy predicted prediction predictions prettytable product proportion purchase python queries query question questions random refund remaining reproducibility reset return samples seed set shipping split step store subscription subset support supported table technical test testing text textual tf tfidfvectorizer train training tree trees two user value various vectorizer warranty",
        "url": "/Random-Forest-Classifier-Model.html"
    },
    {
        "id": 5,
        "title": "Scikit-learn.html",
        "content": "scikit learn accuracy actions actual algorithms allows analysis apis auc beginners best box bunch calculate categorical classifier clf code comparison corresponding cross data dataset datasets dbscan decision dictionary dimensionality documented efficient external features files flowers following forest forests function good grid high hyperparameter identical import initializes integration iris joblib key label labels later learning length libraries library linear machine machines matplotlib metrics missing model modeling models normalization numpy object open output overview pandas pca performance petal pickle points popular precision predicted predictions predicts preprocessing professionals python random range recall reduction regression results roc sample samples science scikit scipy search selection sepal set sets setup simple sne source specific summary supervised svm target test testing tools top toy train trained training trees unsupervised use used validation values variables variety vector well wide widely width yes",
        "url": "/Scikit-learn.html"
    },
    {
        "id": 6,
        "title": "Vector-Database.html",
        "content": "vector database abnormal accuracy ai angular annoy annoyindex anomalies anomaly api apis applications associated audio behavior bert billions case cases characteristics classification client clustering code collection common connect connection content control count cpu creates critical data database databases datasets db dbscan dense detection dimension dimensional dimensionality distance distances documents driven ecosystem efficiency efficient embeddings environments essential euclidean event example explanation external f facebook faiss fast faster feature features file first flat focuses format full function gcp generated gpt gpu high hnsw hosted hosting id ids image images import index insert inserts install integration item items ivf k key keywords labels lancedb language large latency learning library local low machine management manhattan match meaning means memory metadata metric metrics ml models modern natural nearest need needs neighbor neighbors new nlp nn np numerical numpy open outliers overview path perform performance pinecone pipelines points processing production products queries query querying random randomly range real recommend recommendation regression result results retrieval retrieve role scalability scale scales scenarios score search searches self semantic semantically services similar similarity situations small source space specialized specified spotify steps storage store supports systems table tasks text throughput time top traditional transaction tree type types unusual usage use user users various vector vectors version visual wide workloads world",
        "url": "/Vector-Database.html"
    },
    {
        "id": 7,
        "title": "Keras.html",
        "content": "keras accessible accuracy activation adam algorithms analysis api artificial backpropagation basic best biases binary blocks building case channel channels churn class classes classification cnn cnns cntk code colored complex complexities complexity components computation computational connected connections consistent convolution convolutional core corners correct cpu customer cycle data dataset decision deep dense detection developers diagnosis differences different digit digits dimensional dimensions direction edges either error example facial faster feature features feedback feedforward filters final flatten flexibility fnn forward frameworks fraud fully function functional functions generation gpu gpus grayscale grid handwriting handwritten hardware hidden hierarchies high highly image images import important information input keras kernels key labels layer layers learning level library linear linearity loops loss low lstm many map maps max medical metrics minimal mnist model models multi network networks neural node nodes non number numpy object objects one open operations optimizer optimizers output overview parameters part patterns performance pixel platform pooling prediction predictions probabilities process processing propagation recognition recognizing rectified reinforcement relu rgb scaler sequential sets sgd sigmoid simple size softmax source spatial specialized stack standardscaler structure structured summary support synthetic tabular task tasks tensorflow testing text textures theano top training type unit use variety vector video weights x",
        "url": "/Keras.html"
    },
    {
        "id": 8,
        "title": "Gunning-Fog-Index.html",
        "content": "gunning fog index account algorithms analysis applications average code complex content count creation def division document education english example exclamation explanation expressions first fog following formal formula function general given gunning higher implementation import index language length levels mark marks natural nlp number patterns percentage period processing punctuation question readability readership reading regular return score sentence sentences steps syllables test text texts three various vowel vowels way word words writing years",
        "url": "/Gunning-Fog-Index.html"
    },
    {
        "id": 9,
        "title": "PyTorch-Sentiment-Analysis-Model.html",
        "content": "pytorch sentiment analysis model accuracy acting amazing analysis backpropagation base batch bcewithlogitsloss bertmodel berttokenizer book build class classification complete connected criterion dataloader dataset decent dimension direction dtype epoch evaluation example examples existing expanded experience extra false film fully function great horrible idx import inference input labels layers linearity logits loop loss masterpiece mode model module movie negative nn non optimizer optional output outputs padding performance performances plot positive prediction predictions preds prettytable print python raw report save saved sentiment sentimentclassifier sigmoid statement statements story storytelling table text textdataset texts threshold time tokenizer tokens torch trained training transformers true truncation two use values waste watch worst year",
        "url": "/PyTorch-Sentiment-Analysis-Model.html"
    },
    {
        "id": 10,
        "title": "Time-Complexity-Big-O-Notation.html",
        "content": "time complexity big o notation access addition adjacency algorithm array average avl b balance balanced balancing bfs big binary black brute bst bubble case cases certain children collisions complexities complexity computer constant data databases delete deletion deletions design dfs division double e edges efficiency efficient element elements example execution exponential extra factor file fixed force graph hash head heap height index indexing input insertions keys leaf least level linear linked list logarithmic loop luzbetak max memory merge merging min minimum much n nature nested new nodes notation number operations performance permutations priority problem process properties queue rebalancing red resizing retrieval root runtime salesman scenario search selection set size sort sorted space splitting step storage structure structures systems table time traveling tree trees use v vertices way worst",
        "url": "/Time-Complexity-Big-O-Notation.html"
    },
    {
        "id": 11,
        "title": "PyTorch.html",
        "content": "pytorch acceleration arrays audio automatic backward basic built class classes common computation computational computer connected criterion crossentropyloss custom dataset datasets deep developers differentiation digits dimensional epoch example faster features final flexible forward fully function gpu gradients graphs image import inputs key labels language layer layers learning libraries library logits loop loss machine mnist model models module multi natural net network networks neural nlp nn numpy open optim optimization optimize optimizer output outputs platform pre preprocess processing pytorch relu researchers simple source speech strong support tasks techniques tensors torchaudio torchtext torchvision totensor training trainloader transform variety various vision wide x zero",
        "url": "/PyTorch.html"
    },
    {
        "id": 12,
        "title": "Python-Syntax-Highlighting.html",
        "content": "python syntax highlighting age b bash cd computer def desc echo fmt golang highlighting import int luzbetak main mkdir name order package python select sql syntax users",
        "url": "/Python-Syntax-Highlighting.html"
    },
    {
        "id": 13,
        "title": "Managed-External-Live-Tables.html",
        "content": "managed external live tables actual automated automation aws azure batch blob case checks cloud data databricks datasets dbfs def default delta dependencies differences dlt etl example execution external feature file files framework hdfs id import ingestion int internal key lifecycle live location managed management metadata monitoring name output persistent pipeline pipelines processing quality real shared storage streaming string system table tables tasks temporary time transformation underlying use users workflows",
        "url": "/bricks/Managed-External-Live-Tables.html"
    },
    {
        "id": 14,
        "title": "PySpark-Coding-Examples.html",
        "content": "pyspark coding examples age aggregate aggregation average back based categories category centralized clause code coding col column commands computer condition count csv customers data databricks dataframe dataframes def default defined delta department desc df distinct duplicate email example exercises file filter format formats function greater group guide import inner introduction join lake lakes limit loading luzbetak missing name none number occurrences operation order orderby parquet people prefix price pyspark queries read records repository result rows salaries salary sales sample scale select show spark sparksession specific sql stringtype structured sum text top total transformation transformations two udf unique unstructured user using value values various word words world write writing",
        "url": "/bricks/PySpark-Coding-Examples.html"
    },
    {
        "id": 15,
        "title": "RDBMS-Schemas.html",
        "content": "rdbms schemas central charts child clear common complex complexity connections constellation data database databases denormalized dimension dimensions fact faster fewer flat foundational galaxy hierarchical integrity joins management many marts multiple needs network non normalizes organizational parent performance queries query rdbms redundancy related relational relationship relationships schema schemas several simple simpler single snowflake specific star structure systems table tables tree warehouses",
        "url": "/bricks/RDBMS-Schemas.html"
    },
    {
        "id": 16,
        "title": "PySpark-Data-Streaming.html",
        "content": "pyspark data streaming abstraction api application averages backpressure based batch batches capabilities checkpointing checkpoints cluster code computation consistent continuous core counts data dataframes dataset datasets declarative development different discretized distributed dstream dstreams ease ecosystems evolution failures fault flexibility flume frames handling hardware hdfs information input integrates integration kafka kinesis larger live logs loss lost metrics micro network node nodes operations original overwhelming patterns period process processing pyspark rate rdd rdds real resilience resilient resources running scalability sensor sliding small sockets source sources spark specific sql state stateful stream streaming streams structured support system tcp time tolerance transformations trends tweets various volumes window",
        "url": "/bricks/PySpark-Data-Streaming.html"
    },
    {
        "id": 17,
        "title": "Databricks-Delta-Lake.html",
        "content": "databricks delta lake acid aggregated analysis approach architecture audits availability batch big broad bronze capabilities collaboration concurrent consistency controlled copy data databricks datasets debugging delta design durability ecosystem efficient external failures fast feature flexibility flink given handling historical lake large management massive medallion metadata modifications need open optimized organizations partners platforms point presto processing protocol quality queries raw refined reliability scalable scale scenarios seamless secure sharing single streaming support tiers time tools transaction travel trino types unified users various versioning versions workloads",
        "url": "/bricks/Databricks-Delta-Lake.html"
    },
    {
        "id": 18,
        "title": "RDBMS-Snowflake-Schema.html",
        "content": "rdbms snowflake schema additional advanced approach attributes central characteristics complex complexity cost costs data database design difference differences dimension dimensions duplicated environments example extension fact fewer higher increased indexing integrity joins key layers level levels multiple need normalization normalized normalizing performance piece priority process queries query reduced redundancy related relational relationships scenarios schema separate several shape simplicity single slower snowflake space star storage structure structured sub table tables techniques usage variation warehouses warehousing year",
        "url": "/bricks/RDBMS-Snowflake-Schema.html"
    },
    {
        "id": 19,
        "title": "etl-pipeline.html",
        "content": "etl pipeline accuracy additional aggregation analysis apis application applying averages business calculations cleaning cloud common connectivity consistency context conversion convert counts csv currencies data database databases date destination different downtime duplicates efficiently enhancing enrichment ensuring errors etl extract extraction failures files format formats full incremental information integrity irrelevant issues json lake large load loading logic missing needs optimization organization performance points process reference resource retries rules services sources specific structure summarizing sums system tables target transform transformed usage values various volumes warehouse xml",
        "url": "/bricks/etl-pipeline.html"
    },
    {
        "id": 20,
        "title": "Databricks-PySpark.html",
        "content": "databricks pyspark abstractions access acid action advantages aggregation algorithms allocation analysis analysts analytics apache api applications automate aws azure based big business capabilities cases cloud cluster clusters code collaboration collaborative collect collections complexity computation computing count csv data databases databricks dataframe dataframes datasets deep delta deployment df distributed dive efficiency engineers environment etl evaluation example execution experiment extract features file full fundamental gcp handling high import insights intelligence iterative key lake large layer lazy learning level leverage load machine machines managed management manipulation manner members memory metadata mlflow mllib model models multiple notebooks open operations overview pandas parallel performance pipelines platform processing pyspark python queries rdds real resilient resource resources results scalability scalable scale scientists services session sharing source spark sparksession storage stream streaming streams structure structured system tasks team time tolerance top tracking transactions transform transformation use user users visualizations workflows workload workloads",
        "url": "/bricks/Databricks-PySpark.html"
    },
    {
        "id": 21,
        "title": "PySpark-Pivot-Table.html",
        "content": "pyspark pivot table alice analytics application categorical code column columns combination context data dataframe df dictionaries digestible east employee example explanation following format functions group import information list multiple new north one output overview pivot pivoted provided purposes pyspark region reporting sales sample something south spark sparksession sum table tool unique using value values west",
        "url": "/bricks/PySpark-Pivot-Table.html"
    },
    {
        "id": 22,
        "title": "RDBMS-Star-Schema.html",
        "content": "rdbms star schema advantages agegroup amounts analysis attributes category central commerce components customer customerid customername data database date dateid dates de descriptive design details dimension disadvantages e efficient example fact facts flexibility foreign increased joins keys limited links month names normalization number optimized performance popular price product productid productname quantitative quantities quarter queries query rdbms redundancy region requirements resemblance sales schema simple simplicity star storage store storeid table tables warehouse warehousing year",
        "url": "/bricks/RDBMS-Star-Schema.html"
    },
    {
        "id": 23,
        "title": "PySpark-SQL-Functions-Parquet.html",
        "content": "pyspark sql functions parquet age aggregate aggregation average back based categories category centralized clause code col column commands condition count csv customers data databricks dataframe dataframes def default defined delta department desc df distinct duplicate email example file filter format formats function functions greater group guide import inner introduction join lake lakes limit loading missing name none number occurrences operation order orderby parquet people prefix price pyspark queries read records repository result rows salaries salary sales sample scale select show spark sparksession specific sql stringtype structured sum text top total transformation transformations two udf unique unstructured user using value values various word words world write writing",
        "url": "/bricks/PySpark-SQL-Functions-Parquet.html"
    },
    {
        "id": 24,
        "title": "Medallion-Architecture.html",
        "content": "medallion architecture accurate advanced aggregated aggregation aggregations analysts analytics approach architecture availability avro benefits big bronze business cases category cleaned cleaning clear column columns common complex conflicts consistency cost csv dashboards data dataset datasets days decision delta deltacatalog description different domain duplicates electronics end engineers errors facilitate filtering final flexibility focus form formats future gold governance grocery high implementations improvements incomplete information ingestion insights json kpis lake large last latency layer layered layers learning levels lineage logic machine making medallion minimal missing model models multiple new number optimized orders organizations original overview parquet partitioning paths performance petabytes practice primary processing purpose pyspark quality query range raw real records refined refining reporting result sales scalability scale scientists separate separation sets silver sizes source sources spark specific stage stages structured systems tables teams terabytes three tiers today total traceability tracking training transformation transformations two unfiltered unprocessed use users validated values various world",
        "url": "/bricks/Medallion-Architecture.html"
    },
    {
        "id": 25,
        "title": "Medallion-Architecture-Partitioning-Code.html",
        "content": "medallion architecture partitioning code agg aggregated aggregation aggregations alias architecture bronze category cleaning column columns config data dataset days deltacatalog description dropduplicates electronics filter format gold grocery groupby ingestion last layer layers medallion mode new node number optimized orders original partitioning pyspark raw read repartition result sales silver spark sum tables three today total transformation two write",
        "url": "/bricks/Medallion-Architecture-Partitioning-Code.html"
    },
    {
        "id": 26,
        "title": "Managed-External-Tables.html",
        "content": "managed external tables case cases control data database delta directory external lake lifecycle location managed management metadata physical specified storage summary system systems table unmanaged use user",
        "url": "/bricks/Managed-External-Tables.html"
    },
    {
        "id": 27,
        "title": "Column-Shuffle-Repartition.html",
        "content": "column shuffle repartition aggregations alternatives balance balancing case category cluster col column data default efficiency efficient equal example filtering following full goal grouping intention joins key large later load logic multiple nodes number operations oversized parallel partition partitions perfectly points processing pyspark reasonable repartition repartitioning rows share shuffle shuffling smaller spark specific specified splits syntax using value values",
        "url": "/bricks/Column-Shuffle-Repartition.html"
    },
    {
        "id": 28,
        "title": "Optimizing-Join-Queries.html",
        "content": "optimizing join queries accessed active adequate allocation amount analysis anomalies architectures archive batch batches bottlenecks buffer buffering cache caching check clause columns common complex composite condition conditions considerations constraints continuous correct cost costly criterion ctes data database datasets date defragmentation denormalization design different dimension disk disks efficient environment example excessive execution expensive explain expressions fact faster files filter filtering filters flexible foreign fragmentation frequently full functions hardware histograms implement incorrect increased index indexed indexes indexing infrastructure inner insights insufficient join joins key large left legacy less limited loop maintenance management materialized memory method methods model monitoring multiple mysql need nested old older ones operation operations optimization optimize oracle order parallel partition parts performance plan pools potential processing processors proper pruning purge queried queries query redundancy redundant region regular regularly repeated resources result results retrieval rewrite right running scalability scans schema selective separate set simpler size smaller solutions specific ssds star statistics steps storage subqueries sufficient summary system table tables tasks techniques time tools tune type types unnecessary usage views volume warehouse warehousing write",
        "url": "/bricks/Optimizing-Join-Queries.html"
    },
    {
        "id": 29,
        "title": "Relational-Databases.html",
        "content": "relational databases accuracy acid advantages algebra analysis analytical analytics another apis atomicity attribute attributes benefits better business caching category central centralized clear codd column columns complex compliance comprehensive concepts consistency constraints current data database databases datasets decision denormalized design dimension edgar enforced entities etl extract fact fast features files finance flat foreign functions heavy historical identifier improved indexing integrity intelligence key keys language large load making marts multidimensional multiple normalized nothing olap oltp one online operational operations performance predefined primary process processing properties purposes queries query querying read reads record records redundancy reference relational relations relationships reporting row rows sales schema simple single slice snowflake source sources specific sql standardized star state stores structure structured subsets table tables target techniques theory time transaction transactional transactions transform transformed trend truth unique users valid various view volumes warehouse warehouses warehousing writes",
        "url": "/bricks/Relational-Databases.html"
    },
    {
        "id": 30,
        "title": "PySpark-Lazy-Evaluation.html",
        "content": "pyspark lazy evaluation ability action actions actual acyclic amount benefits calculations cluster complex computation computing concept count dag data dataframe deferred directed distributed driver efficiency efficient entire environments evaluation example examples execution existing external fewer filter filtering final graph intermediate jobs key lambda large lazy logical manner map mapping memory necessary new one operations optimization optimizations optimize performance pipelines pipelining plan plans point print processing program pyspark rdd resource resources result results saveastextfile scalable scale sequence several small spark steps storage subset transformations unnecessary usage",
        "url": "/bricks/PySpark-Lazy-Evaluation.html"
    },
    {
        "id": 31,
        "title": "Delta-Live-Tables.html",
        "content": "delta live tables acid analytics automate automatic batch cases checks clean cleaned col complex constraints creation data databricks declarative def delta dependencies dependency development dlt ease efficiency enforce enforcement entire etl example execution failure flexibility framework handling health immediate import incremental ingestion integration invalid lake learning lifecycle lineage live machine management manual monitoring new observability operational optimizations orchestration output overhead performance pipeline pipelines processing quality raw real return rows schema simple simplified simplifies sources streaming supports syntax tables time tools top tracking transactions transformation transformations travel use valid visibility way workflow workloads",
        "url": "/bricks/Delta-Live-Tables.html"
    },
    {
        "id": 32,
        "title": "PySpark-Handling-Missing-Data.html",
        "content": "pyspark handling missing data action algorithms analysis analytics apache api applications backward big binary building cluster col collections column columns common computer computing constant data database dataframes datasets developers different distributed downstream drop evaluation execution fault features fill filling filter flag forward framework function functions fundamental github import imputation indicator instance key language large last lazy learning library lost luzbetak machine machines map median memory method methods missing missingness mllib mode model modeling models named nature null numeric objects observation open operations optimizations parallel performance plan planning popular powerful preprocessing processing programming pyspark python queries query rdds regression relational remove requirements resilient rows scale several single source spark specific specified sql string structure structured subset summary system table task techniques tolerance tools transformations valid value values various window",
        "url": "/bricks/PySpark-Handling-Missing-Data.html"
    },
    {
        "id": 33,
        "title": "PySpark-Questions-Answers.html",
        "content": "pyspark questions answers action actions algorithms answers apache api apis big catalyst cluster clusters collection columns computation computing concept control count data database databases dataframe dataframes dataset datasets difference distributed driver easier efficient element elements entire evaluation example execution existing external features filter flatmap flow function fundamental github high higher inner input interface iterative join joins key large lazy level lineage list logical low luzbetak machines manipulation map memory multiple named new objects one open operations optimizer pandas parallel parallelism parallelized physical plan plans processing program pyspark python questions rdd rdds relational resilient results rules scale semi single source spark storage structure structured system table tables tasks tolerance transformation transformations two various ways",
        "url": "/bricks/PySpark-Questions-Answers.html"
    },
    {
        "id": 34,
        "title": "menu.html",
        "content": "menu data databricks devops github learning machine programming search",
        "url": "/_includes/menu.html"
    },
    {
        "id": 35,
        "title": "footer.html",
        "content": "footer kevin luzbetak",
        "url": "/_includes/footer.html"
    },
    {
        "id": 36,
        "title": "debugging-kubernetes-performance.html",
        "content": "debugging kubernetes performance agent anomalies another api application applications approach autoscaler bottlenecks c calico capacity cause cilium cli clues cluster clusters code collection combination communication components conclusion congestion container containers cpu crashes dashboard dashboards debugging degradation dependencies deployments describe description detailed details different disk displays distributed entire environment error errors events experience external failed features fio flow flows functions go grafana graphical health high historical horizontal hpa htop hubble indicators information interactions iops iotop issue issues istio java journalctl jvm key kubectl kubelet kubernetes latencies latency leaks level limits load logs loss measure memory messages metrics misconfigurations monitoring mounts n name namespace native nature network networking node nodes object observability oomkilled open operations overview packet performance persistentvolumeclaim persistentvolumeclaims planning plugins pod pods policies policy pressure primary probes problems profiler profiling prometheus pvc py python rates real related reliable request requests resource resources restarts root running runtime scaling service slow smooth snapshot solution solutions source space specific spy ssh stack status steps storage swapping symptoms systematic testing tests throttling time tool tools top traces tracing traffic trends troubleshoot u ui unusually usage use variety vertical visualization vpa warnings wasted weave web",
        "url": "/devops/debugging-kubernetes-performance.html"
    },
    {
        "id": 37,
        "title": "github.html",
        "content": "github access account actions admin another answer answers applications asked authentication authorization automate automated based best blogs board branch bugs building changes ci cloud code codebase coding collaboration comment common community conclusion conflicts content continuous contributions contributor contributors control copy core deployment developer developers development directory documentation environments experience feature features files followers forked forks git github global group history integrates integration interview interviews issue issues job kanban key level lines local machine main maintainer management members merge method model modern modifications oauth offers open organization organizations original others overview owner pages party permissions personal pipelines platform platforms points popular powerful practices process production project projects providers pull quality questions range rbac remote repositories repository request requests resources review reviews revisions role roles saml separate services site sites social software source stars static style target tasks team teams testing tests third tool tools tracking users version web websites wide wikis workflow workflows yaml",
        "url": "/devops/github.html"
    },
    {
        "id": 38,
        "title": "general-101.html",
        "content": "general 101 ability abstractions acceptable access accuracy acid action acyclic adheres advantages aggregation airflow alerts algebra algorithms aligns allocation amazon amounts analysis analysts analytical analytics another apache api apis applications atomicity attribute attributes automate automated automatic automating automation aws azure based basis batch benefits best better big branch branches branching bug build building business caching capabilities capacity cases category cd central centralized certain chance change changes checks ci clear cloud cloudformation cloudwatch cluster clustering clusters codd code codebase collaboration collaborative collect collection collections column columns commit common complex complexity compliance comprehensive computation compute computing concepts conditions configuration configurations conflicting conflicts considerations consistency consistent constraints container containerized continuous control count cross csv current custom cyclic dag dags data database databases databricks datadog dataframe dataframes dataset datasets date dates decision deep delay delta denormalized dependencies deployment design developers development df diagnosing different dimension directed distributed dive docker documentation downstream driven duplicated duplication edgar efficiency elastic elt encryption end enforced engineering engineers ensure ensures entire entities environment environments error errors etl evaluation event events every example execution expectations expected experiment extract fact failed failure failures fast feature features field fields file files finance fixes flat flexibility focus foreign formal formats full functions fundamental gcp general git github gitlab graceful graphs great handling heavy high historical iac idempotency idempotent identifier identifiers identity implement import improved incoming inconsistent indexing infrastructure insights instances integrates integration integrity intelligence intervals intervention issue issues iteration iterative jenkins key keys kubernetes lake lambda language large layer lazy learning level leverage load location logging logic long luigi machine machines main making managed management manipulation manner manual marts mechanisms members memory merge merging metadata mlflow mllib model models modern monitor monitoring mr multidimensional multiple mysql new normalized notebooks nothing null numbers numeric object olap oltp one online open operational operations orchestrated orchestration orchestrator orchestrators order others outcome overview pandas parallel parallelism part parts performance pipeline pipelines platform platforms point popular post postgresql pr practices predefined prefect previous prices primary process processes processing product production proper properties protection provisioning pull purposes pyspark python quality queries query querying ranges rapid rdds rds read reads real record records recovery redundancy reference regular relational relations relationships reliability repeatability reporting repositories repository request requests resilient resizable resource resources response result results retries retry reviews row rows rules running sales scalability scalable scale scaling scheduled scheduling schema scientists secure security semi sensitive separation sequence server serverless servers service services session setup shared sharing simple simplicity single slice small snapshot snowflake source sources spark sparksession specific specified sql stable stages standardized standards star state states step storage stores strategies strategy stream streaming streams structure structured subsets system systems table tables target task tasks team teams techniques technologies temporary terraform test testing tests theory thresholds time tolerance tool tools top traceability track tracking transaction transactional transactions transform transformation transformations transformed travel trend trigger triggering troubleshooting truth two types unique uniqueness unit updates upstream use user users valid validated validates validation validations value values various version versions view virtual visualizations volumes warehouse warehouses warehousing way web workflows workload workloads writes",
        "url": "/devops/general-101.html"
    },
    {
        "id": 39,
        "title": "apache-nifi.html",
        "content": "apache nifi ability aggregation analysis apache apis approach audit authentication authorization automation based cases cloud common complex compliance control csv custom data databases debugging delivery destinations detailed detection developers devices different diverse drag drop efficient encryption enrichment environments external features filtering finance flow flows formats formatting fraud friendly ftp government healthcare high http industries ingestion integration interface iot json kafka key lakes large lineage logs manner mechanisms monitoring multi nifi non open organizations overview pipelines plugins premises privacy processing processors programming protocols provenance range real routing scalability scenarios seamless secure services source sources ssl system systems tasks technical telecommunications tenant throughput time tool trails transfer transformation transformations use user users various visual volumes warehouses web wide xml",
        "url": "/devops/apache-nifi.html"
    },
    {
        "id": 40,
        "title": "docker.html",
        "content": "docker access application applications base center cloud commands compose consistency container containerization containerized containers control creation data dependencies developers development different docker dockerfile ecosystem environment environments faster features file files filesystem host hub image images increased instructions isolated kernel key load local machine machines management multi multiple networking orchestration os points portability previous problem process processes production repository reproducibility scalability scaling scope security series startup swarm system templates testing text times tools variables vast version versions virtual vms vulnerabilities",
        "url": "/devops/docker.html"
    },
    {
        "id": 41,
        "title": "apache-airflow.html",
        "content": "apache airflow acyclic airflow amounts analysis apache architecture author based bashoperator celery changes cloud code communication complex configurable connection correct custom dag dags data databases debugging delays dependencies devops different directed distributed dynamic engineering errors etl extensibility external failure features flow generation graph graphs hooks integrates integration integrations interface intervals key kubernetes large learning limits load logging machine managing mechanism mechanisms modular monitoring multiple needs node notifications number open operators orchestrate order pipeline pipelines platform platforms plugins points processes programmatically progress python pythonoperator relationships retry rich scalability schedule scheduling science seamless sensors services set small source specific specified sql step systems task tasks technologies triggers troubleshooting types ui updates user various versioning web workers workflow workflows xcoms",
        "url": "/devops/apache-airflow.html"
    },
    {
        "id": 42,
        "title": "Kubernetes.html",
        "content": "kubernetes access active actual address amount answer answers api apiversion app application applications approach appropriate architecture architectures asked automate automated autoscalers autoscaling availability balancing based basic capabilities capacity case cases certificates changes charts claims cloud cluster clusters cncf command communication community complex component components computational computing conclusion conditions configmaps configuration conflicts constraints container containerized containers control controller controllers core count coupled cpu cpus creation custom data databases declarative default definition dependencies deployable deployment deployments desired difference different distributed docker downtime easy ecosystem efficiency elk environment environments etcd example execution experience external f failed features field file following foundation fractional functionality given google granular half hand healing health healthy helm hierarchy high highest horizontal host hosting hpa http https hub identity image images impact individual information infrastructure ingress instance integrations interview interviews ip isolated isolation issues job kernel key kind kube kubectl kubelet kubernetes labels least level levels libraries lifecycle lightweight limit limits load loads logging logs lowest machines main management manager master matchlabels maximum mechanism memory metadata metrics microservices millicores minimal monitoring much multi multiple name namespace namespaces native nature necessary network new nginx node nodes number object observed old one ones open operations operators orchestration overconsuming overview package parts passwords performance persistent physical place plane platform pod pods points policies port portable ports powerful previous private process processes progress proxy pv questions rate rbac registries reliable replicas replicaset replicasets request requests resource resources restarts reusable revision rich risk role rollback rollbacks rolling rollout rollouts routing running runtime scalability scalable scale scaling scheduler scheduling secrets secure security select selector self sensitive server services set settings shared simple simplest simplifies single smallest snapshots source spec specific specification specifications specified ssl stack standards state stateful statefulset statefulsets stateless status storage store strategy sufficient summary system systems tasks template termination three tightly time tls tokens tool tools traditional traffic turn two types typically understanding undo unhealthy unique unit units update updated updates usage use users utilization value varying vcpu version versions virtual volume volumes vulnerabilities way worker workloads yaml",
        "url": "/devops/Kubernetes.html"
    },
    {
        "id": 43,
        "title": "software-delivery.html",
        "content": "software delivery actions another ansible application applications artifact artifactory artifacts aspects assurance automating automation aws binaries bitbucket building categories centralized chef ci cloud cloudformation code configuration containerization containerized containers continuous control data delivery deployment development different distributed docker elk entire environment environments formats frequent functionality functions git github gitlab grafana hosted industry infrastructure initial integration jenkins key kibana kubernetes legacy lifecycle logging logs logstash management manager metrics modern monitoring multiple nexus open orchestration package performance pipelines platform platforms popular practices process production projects prometheus providers puppet quality recipes reliability reliable repositories repository running scalability scaling server service shipping software source sources stack staging subversion svn system task tasks terraform testing tool tools top tracking travis unit universal updates use users various version writing",
        "url": "/devops/software-delivery.html"
    },
    {
        "id": 44,
        "title": "bashrc.html",
        "content": "bashrc argument clear cp echo else eval exec extension f fi file files first function grep keyword l least linux local ls max mkdir name one open os p py python replace rg rnw search second shift spy text tpy two type",
        "url": "/devops/bashrc.html"
    },
    {
        "id": 45,
        "title": "Python-Search-Algorithms.html",
        "content": "python search algorithms algorithm algorithms another arr array base binary case containing current def element elements first function half halves high index intersection iteration left length list lists merge mid middle output pivot process python quick result return right search second single sort target two x",
        "url": "/programming/Python-Search-Algorithms.html"
    },
    {
        "id": 46,
        "title": "Python-String-Algorithms.html",
        "content": "python string algorithms actual algorithm algorithms anagram anagrams analysis args argument array base binary boolean cases char character characters check checking common comparison correction corresponding cost def deletion deletions detection distance distances dna dp dynamic edits element elements elif equal error example false first fizz fizzbuzz function hamming import indices input insertion insertions int integer j karolin language last lcs length levenshtein list longest maximum measure metric minimum n natural non none number numpy one operation order original output pair palindrome positions processing programming python repeated representation result return returns reverse row second sequence sequences similarity single size sorted spell str string strings subsequence substitutions table true two usage value values versions vowels world",
        "url": "/programming/Python-String-Algorithms.html"
    },
    {
        "id": 47,
        "title": "Python-Coding-Exercise-Algorithms.html",
        "content": "python coding exercise algorithms algorithms bool char character coding def duplicates enumerate example exercise fibonacci first int intersection j largest list lists merge non none number nums olleh output palindrome problem range repeated return sequence sorted str string sum target true two usage vowels w world",
        "url": "/programming/Python-Coding-Exercise-Algorithms.html"
    },
    {
        "id": 48,
        "title": "101.html",
        "content": "101 actual algorithm algorithms anagram anagrams analysis another args argument arr array base binary boolean case cases char character characters check checking common comparison complement containing correction corresponding cost current def deletion deletions detection distance distances dna dp duplicates dynamic edits element elements elif equal error example false fibonacci first fizz fizzbuzz function half halves hamming high import index indices input insertion insertions int integer intersection iteration j karolin language last lcs left length levenshtein list lists longest loop maximum measure merge metric mid middle minimum n natural nested non none number numbers numpy nums one operation order original output pair palindrome pivot positions problem process processing programming python quick recursive remaining remove repeated representation result return returns reverse right row search second sequence sequences series similarity single size sort sorted specific spell str string strings subsequence substitutions sum table target true two usage value values versions vowels world x",
        "url": "/programming/101.html"
    },
    {
        "id": 49,
        "title": "Python-Programming-Language.html",
        "content": "python programming language access algorithms anonymous arguments async asynchronous asyncio attributes await behavior break cases classes closures code collection complexity comprehensions conditional context control counting cprofile csv custom data debugging decorators def default defining dependencies development dictionaries different django dunder efficient encapsulation environments error exceptions explicitness expressions file files flask flexible flow fly frameworks functions garbage generator generators gil guide handling higher idiomatic implications importing inheritance inline iter iterators itertools json key lambda language libraries library like list lists loops management managers managing math matplotlib memory methods mock modules multiprocessing mutable numpy object objects optimization order oriented packages pandas parameters pdb pep performance polymorphism popular practices principles private profiling program programming properties public python pythonic readability readable reading reference requests results scikit sequence sets simplicity special standard statements str structures style sys systems test testing text time timeit tools tuples types understand understanding unit unpacking use values venv virtual virtualenv ways web writing yield zen",
        "url": "/programming/Python-Programming-Language.html"
    },
    {
        "id": 50,
        "title": "mysql-lag-function.html",
        "content": "mysql lag function analysis average avg chronological clause column curdate current daily data date dates day days decimal difference differences explanation filtering four function increase increases inner interval lag last mysql null order outer overview places previous price purpose query result round row rows select sequential series sql time valid value values window",
        "url": "/programming/mysql-lag-function.html"
    },
    {
        "id": 51,
        "title": "Python-Function-OOP-Data-Structure.html",
        "content": "python function oop data structure age alice animal anonymous another argument array async asynchronous asyncio attribute attributeerror author await bark basic bob book buddy call class classes closures code collection common concurrency csv data decorators def defining dictionaries dictionary different dog dunder dynamic element elements encapsulation example expression file func function functions generator generators george greet header headers hello hi higher immutable import individual inheritance item iterator iterators key keys lambda line list lists memory meow methods msg multiple multiprocessing multithreading name numbers object objects order oriented orwell output pair person polymorphism print private process processes program programming python r range reader reading return row rows sample self separate sequence set sets simple single spaces speak square structures target thread threading threads tuple tuples unique unordered value values woof wrapper x yield yields",
        "url": "/programming/Python-Function-OOP-Data-Structure.html"
    },
    {
        "id": 52,
        "title": "Sudoku-Board-Verification.html",
        "content": "sudoku board verification args block board bool checks col column columns completed conditions def definition example expected explanation function given grid inner int list lists logic main matrix module numbers output parameters pprint pretty prettyprinter prints provided purpose puzzle result return returns row rows rules script specified standard start steps sub sudoku sum sums total true value verification",
        "url": "/programming/Sudoku-Board-Verification.html"
    },
    {
        "id": 53,
        "title": "Python-Algorithms.html",
        "content": "python algorithms algorithm argument array complement def element elements fibonacci function indices integer j list lists loop n nested number output recursive remaining result return series sorted sum target two value values",
        "url": "/programming/Python-Algorithms.html"
    },
    {
        "id": 54,
        "title": "algorithms2.html",
        "content": "algorithms2 args character collections comparison counter def deletions distance dp dynamic first hamming import insertions int j levenshtein libraries n necessary number numpy programming returns second string strings substitutions two",
        "url": "/programming/algorithms2.html"
    },
    {
        "id": 55,
        "title": "algorithms.html",
        "content": "algorithms algorithm algorithms anagram anagrams another applications argument arr array article backtracker backtracking base binary bits bitwise boolean bubble calculate case characters check code coding coins combinatorics common complement computational computer conclusion containing cryptography current data def desired different dijkstra distance dp dynamic edges element elements elif engineering examples explanation fibonacci first five fizz fizzbuzz following formula function gcd given graph half halves hamming hash high important index indices information insertion integer integers interviews iteration j key knapsack last left length levenshtein linear list longest loop matrices matrix maximum merge mid middle multiples multiplication n negative nested networks neural nth number numbers operations optimization order original pair palindrome parts passwords paths pivot popular possibilities powerful print problem problems process programming python queens quick range real recursion recursive regression remaining representation result return reverse row salesman science search second selection series set shortest single size smaller solution sort sorted sorting specific stairs steps str string strings structures subproblem subproblems subsequence sudoku sum tables target tasks term three tools traveling trees two types user value values various ways weight wide world x",
        "url": "/programming/algorithms.html"
    },
    {
        "id": 56,
        "title": "Fibonacci-Generator.html",
        "content": "fibonacci generator b code current def definition execution fibonacci first function generator github infinite iteration loop luzbetak next numbers old pages python sequence state statement sum two value values yield",
        "url": "/programming/Fibonacci-Generator.html"
    },
    {
        "id": 57,
        "title": "Amazon-RDS.html",
        "content": "amazon rds advanced amazon analytical api application applications aurora automated availability aws az backend backup backups calls capabilities cases choice cli clicks cloud cloudwatch common compute console consuming costs credentials data database databases demand demands deployments development dms drivers easy encryption engine engines enterprise environment environments example excellent failover features flexible grade hardware high import ingestion instance instances integration isolation key kms layers load managed management mariadb microsoft migration mobile models multi multiple mysql native network operation oracle organizations patching patterns performance point popular postgresql pricing provisioning rds recovery relational reliable replicas reserved resources rest scalability scale security server service services setup several smaller snapshots solution sql ssl standard storage tasks testing time tools transit usage use vpc warehouses warehousing web workflow zone",
        "url": "/aws/Amazon-RDS.html"
    },
    {
        "id": 58,
        "title": "AWS-CloudWatch.html",
        "content": "aws cloudwatch access actions activity alarms alerts amazon anomalies anomaly application applications automate automated automation aws balancers behavior build cases certain changes cloud cloudwatch collection common comprehensive conditions configure cpu custom dashboards data defined detection ecosystem efficiency enable entire environment environments errors essential eventbridge events example failure features filters functions gain health immediate infrastructure insights instances interface issues key lambda learning load log logs machine memory metric metrics monitor monitoring notifications observability operational operations part patterns performance premises problems rds real related reliability resource resources response responses security service services single specific thresholds time tool unauthorized unusual usage use utilization view visibility visual web workflow",
        "url": "/aws/AWS-CloudWatch.html"
    },
    {
        "id": 59,
        "title": "Amazon-S3.html",
        "content": "amazon s3 access accessed amazon amount amounts analysis analytics api applications archival archive archiving athena automated availability aws backup backups big bucket buckets cases cdn centers class classes cloud cloudfront common compliance computing content controls cornerstone cost costs custom data datasets deep delivery different disaster dispersed distribution diverse documents durability effectiveness emr encryption features flexibility frequently geographically glacier high hours ia iam identity images infrequent infrequently intelligent internet key lakes lambda languages large layers lifecycle long lower lowest management many minutes multiple needs number object objects one option options patterns policies pricing processing programming range rapid reasons recovery redshift regions reliability replication requests rest restful retrieval scalability scalable scale sdks security serverless service services simple single sources specific spectrum sql standard static storage storing term tiering tiers times tools transfer transit transition two unlimited usage use users variety various versioning versions videos virtually web wide zone",
        "url": "/aws/Amazon-S3.html"
    },
    {
        "id": 60,
        "title": "ETL-Pipeline-AWS.html",
        "content": "etl pipeline aws acceleration access activity alarms amazon analysis analytical another apache api apis archival auditing auto automation aws batch big buckets calls catalog cleaned cloudtrail cloudwatch complex compliance config create data database databases datasets define dependencies dynamodb elastic emr encrypt etl events external failures flow frameworks fully functions glue hadoop health iam identity ingestion inspector internal issues job jobs key kinesis kms lake lambda large load loading log logging logs manage managed management mapreduce metadata monitor monitoring needs nosql option orchestration overall party performance pipeline policies processing purposes queries raw rds real redshift regulations relational reporting resources rest roles scale scaling schedules schema security sequence service services simple sources spark specific step storage store streams third time track transfer transform transformation transformations transit trigger use various warehouse workflow",
        "url": "/aws/ETL-Pipeline-AWS.html"
    },
    {
        "id": 61,
        "title": "AWS-EMR.html",
        "content": "aws emr access advanced algorithms amazon amounts analysis analytics apache aws batch big businesses cases cloud cluster common complex configuration control costs data datasets dynamodb ecosystem effective elastic emr encryption environment etl example features flink framework frameworks hadoop hbase hive iam infrastructure instances integration isolation job jobs key languages large layers learning machine managed mapreduce mllib multiple necessary needs network options others pig platform presto pricing processed processing provisioning python raw real redshift resources rest results running scala scalability scale security service services spark spot sql storage store streaming tasks termination time transformations transit underlying use vast warehousing workflow",
        "url": "/aws/AWS-EMR.html"
    },
    {
        "id": 62,
        "title": "AWS-Glue-Workflow.html",
        "content": "aws glue workflow amazon analytics arrival automation aws bucket cases catalog cloudwatch common completion complex comprehensive conditional configuration configure console coordinate correct crawler crawlers custom data define dependencies destinations different driven editor error etl even event events example execution failure feature features flexibility flow flowchart glue handling ingestion integrated integration interface issues job jobs lake load loading logging logic management metadata monitor monitoring multiple necessary orchestrate orchestration order parallel part path paths pipelines predefined previous processes processing progress real redshift scale scheduled schedules sequence set solution sources status success tasks time transformation transformations trigger triggers troubleshoot upstream use various visual warehouse warehousing workflow workflows",
        "url": "/aws/AWS-Glue-Workflow.html"
    },
    {
        "id": 63,
        "title": "AWS-Kinesis-Data-Streams.html",
        "content": "aws kinesis data streams amazon analytics analyzing applications aws cases centralized common data distributed etl event features fly full ingestion insights integration interactions key kinesis lambda large log logs metrics monitoring name personalization phase pipeline process processing real redshift scalability service services sources streaming streams time tracking use user various volume",
        "url": "/aws/AWS-Kinesis-Data-Streams.html"
    },
    {
        "id": 64,
        "title": "AWS-Step-Functions.html",
        "content": "aws step functions access amazon another api application approvals automate automation aws batch business call calls cases common completion complex console coordination data days decision defined deployment design different distributed dynamodb easy ecs editor end environment error errors etl evaluation even example executes execution external extraction failed fault features final flowchart function functions glue handling human iam infrastructure input integration interface jobs json key lambda language learning loading long machine making manage management microservices model monitoring months multiple orchestrate orchestration output path pipelines policies preparation process processes processing redshift reliability reliable roles running scalability sdk security serverless servers service services start state states step steps storage systems task tasks tolerance training transformation transitions trigger use validation various visual workflow workflows",
        "url": "/aws/AWS-Step-Functions.html"
    },
    {
        "id": 65,
        "title": "AWS.html",
        "content": "aws access accurate ad amazon analytics assets athena auditability automatic aws cases catalog cataloged centralized common component configuration control core crawlers data databases date define different discovery emr environment etl evolution example fast features flow glue governance history hoc iam identity integrates integration job jobs key lake lakes landscape lineage loading manage management manual metadata monitor partitions pipelines place policies powerful process processes queries query redshift reference repository schema schemas security services single sources spectrum storage stores strategy structures tables time tool track tracking transformations transforming transparency updates use users various versioning warehouse warehouses workflow",
        "url": "/aws/AWS.html"
    },
    {
        "id": 66,
        "title": "AWS-Config-Inspector.html",
        "content": "aws config inspector account action actionable actions adherence alerts analysis applications approach assessment assessments audit auditing automate automated aws basis best better breaches capabilities cases change changes checks ci clear cloudtrail common compliance compliant config configuration configurations configure continuous controls current define defined demand dependencies deployments desired detailed deviations devops disaster dss enable environment evaluation example execute execution exposed external features findings generate governance historical iam identified impacts improvement incident incidents industry insecure inspector integration internal intervention inventory issues key lambda logs management manual monitoring non notifications ongoing operational organizational part patches pci pipeline planning policies ports posture potential powerful practices predefined process recommendations recommended recorded recovery regular regulations regulatory relationships remediate remediation report reports requirements resource resources response review risks rules schedule scheduled secure security service services set sns software standards state status targets templates thorough time track troubleshooting unpatched use view vulnerabilities vulnerability way workflow",
        "url": "/aws/AWS-Config-Inspector.html"
    },
    {
        "id": 67,
        "title": "KMS-Key-Management-Service.html",
        "content": "kms key management service access activities additional api application applications approach audit auditing authenticity automatic aws behalf best cases centralized cli cloud cloudtrail cmk code common communications compliance configuration consistent console control created cryptographic custom customer customers data define deletion digital dynamodb ebs encrypt encryption environment example feature features granular hardware highly hsms iam industry information integrated integrity key keys kms lambda layer level lifecycle manage managed management managing master minimal modules ongoing operations others permissions policies practices protection providers range rds regulations regulatory repository requirements rest rotation saas sdk security sensitive service services signing single solution specific standards store transit unified usage use users various wide workflow",
        "url": "/aws/KMS-Key-Management-Service.html"
    },
    {
        "id": 68,
        "title": "Lambda-Serverless-Computing.html",
        "content": "lambda serverless computing access actions ai aliases amazon api apis application applications assistants automated automatic automatically automation availability aws backend behavior c cases changes charges chatbots code common complex comprehend compute computing cost custom data database databases design development devices different dynamodb effective efficiency environment environments etl even event events executes execution external extract file files fine flexibility function functions gateway generating grained handle high http identity images incoming information infrastructure input instances integration intervention invocations iot java lakes lambda languages levels log logic management managing manual many message messages milliseconds multiple new notifications number orchestration overhead packaging performance permissions persistent power pricing process processing production programming provisioning python queues range rds real records rekognition requests resizing resource resources response roles ruby runtime runtimes scalability scaling scenarios secure server serverless servers service services several shifts sns sources specific sqs staging state stateless storage streams system tasks thumbnails time traffic transform transformation trigger triggers underlying usage use user variables variety various varying versioning versions videos voice web wide workflows",
        "url": "/aws/Lambda-Serverless-Computing.html"
    },
    {
        "id": 69,
        "title": "Auto-Scaling-EC2-EMR.html",
        "content": "auto scaling ec2 emr action activities amazon amount application applications auto automated availability aws balancing batch big build capacity cases changes checks ci cloudwatch cluster clusters common complexity configure consistent continuous cost costs cpu current custom data day demand deployment desired devops disaster dynamic effective effectiveness efficiency elastic elb emr environment environments events example failed features flexible group health high increases instances integration intensive job jobs key levels load mapreduce memory metrics monitor necessary new nodes number ones operations optimal optimization optimize patterns performance pipelines policies powerful predefined predictable processes processing quick real recovery resource resources response review right scale scaling scheduled schedules seamless service services set size solution specific target test time timely times tracking traffic unhealthy unpredictable usage use utilization way web week workflow workload workloads",
        "url": "/aws/Auto-Scaling-EC2-EMR.html"
    },
    {
        "id": 70,
        "title": "AWS-CloudWatch-Events.html",
        "content": "aws cloudwatch events action actions adjustments alerting alternate api application applications architectures auditing audits automate automated automation aws backups building calls cases change changes checks cloud cloudwatch common complex compliance component components conditions corrective corresponding criteria cron custom data detailed driven ecosystem efficiency environment error errors event events example execution failed features filtering flexible function functions handle handling health infrastructure instance instances intervals key lambda load log logging logic logs mechanisms monitor monitoring near needs notification operations performance periodic powerful processing real regular relevant reliability resources response responses retry review robust rotation rule scheduled scripts security service services sns source specific state step stream system target tasks time trigger triggering triggers troubleshooting unnecessary use way workflow workflows",
        "url": "/aws/AWS-CloudWatch-Events.html"
    },
    {
        "id": 71,
        "title": "AWS-Glue-ETL-Service.html",
        "content": "aws glue etl service actual amazon analysis analytics another apache args argument automatically aws basic batch bucket cases catalog cleaning code commit common completion context crawlers custom data database databases definitions desired different discovery distributed either environment etl example explanation extract features field filtering format frame fully glue gluecontext hood import infrastructure initialization initialize input integration interface intervals intervention job jobs json key kinesis lakes less load loading location managed manual mapping metadata name object optimal output part paths performance preparation process processing provisions python range rds real records redshift relational required resources result results scala scalability scale scales scenarios schema script seamless serverless service services simple simplifies sources spark sparkcontext specific step storage store stores streaming studio table target time transform transformation transformations transformed transforming types usage use using variety various visual warehouses web wide work workflow workload",
        "url": "/aws/AWS-Glue-ETL-Service.html"
    },
    {
        "id": 72,
        "title": "S3-Transfer-Acceleration.html",
        "content": "s3 transfer acceleration accelerated acceleration access additional amazon amounts applications assets aws backups benefits bucket budget business case cases changes clients closest cloudfront cloudwatch common console content control costs critical cross data datasets deadlines desired distance distances distant edge effective enable endpoint example existing expected factor faster feature features file files geographically global identity improved infrastructure key large latency location locations long management media metrics nearest need network new operations optimized paths performance processing region regions reliability requirements review scale scenarios secure security sensitive settings solution speed speeds ssl standard streaming time transfer transfers transit upload uploads use users video workflow workflows world",
        "url": "/aws/S3-Transfer-Acceleration.html"
    },
    {
        "id": 73,
        "title": "IAM-Identity-Access-Management.html",
        "content": "iam identity access management access account actions active activities added addition additional another api application applications attach audit authentication aws best calls cases cloud cloudtrail common compliance compliant consultants controls create credentials critical cross custom define directory enable enhance environment exactly example external factor feature features federation form foundational google granular group groups iam identity individual json key lambda least limited long management mfa microsoft monitor multi needs one organization parties password patterns permissions policies policy powerful practices principle privilege protection provider regulatory requirements resources role roles second secure security service services specific step strict stronger temporary term third tool unauthorized use user users web workflow",
        "url": "/aws/IAM-Identity-Access-Management.html"
    },
    {
        "id": 74,
        "title": "AWS-Glue-Data-Catalog.html",
        "content": "aws glue data catalog access accurate ad amazon analytics assets athena auditability automatic aws cases catalog cataloged centralized common component configuration control core crawlers data databases date define different discovery emr environment etl evolution example fast features flow glue governance history hoc iam identity integrates integration job jobs key lake lakes landscape lineage loading manage management manual metadata monitor partitions pipelines place policies powerful process processes queries query redshift reference repository schema schemas security services single sources spectrum storage stores strategy structures tables time tool track tracking transformations transforming transparency updates use users various versioning warehouse warehouses workflow",
        "url": "/aws/AWS-Glue-Data-Catalog.html"
    },
    {
        "id": 75,
        "title": "AWS-CloudTrail.html",
        "content": "aws cloudtrail access account actions activate activity alarms amazon analysis analyze anomalies api athena audit auditing automated aws bucket call calls cases change changes cloud cloudtrail cloudwatch command common complete compliance comprehensive configurations configure conjunction console dashboards data detailed detecting durable enable environment essential event events example external features files forensic governance historical history incident industry infrastructure insights internal issues key line log logs long management monitoring notifications operational party patterns potential problem record regions regulations relevant requirements resources responses retention risk roles sdks secure security sequence service services specific standards storage store support term third threats time tools track trail troubleshooting unauthorized unusual use user users visibility workflow",
        "url": "/aws/AWS-CloudTrail.html"
    },
    {
        "id": 76,
        "title": "AWS-Redshift.html",
        "content": "aws redshift access amazon analysis analytical analytics aws bi big business businesses cases central cloud cluster clusters columnar commands common complex compression control copy costs data databases datasets decision demand destination destinations driven dynamodb ecosystem effective emr encryption etl example export fast features fully gb glue grained high iam ideal ingestion insights instances integration intelligence isolation jobs key language large load looker making multi network new node organizations parallel performance petabyte petabytes pricing processed processing purposes queries query quicksight real redshift reporting reports reserved resources rest results scale semi service services single solution sources sql standard storage structured support tableau time tools transformation transit use users various visualizations vpc warehouse warehousing workflow workload workloads",
        "url": "/aws/AWS-Redshift.html"
    },
    {
        "id": 77,
        "title": "Apache-Parquet.html",
        "content": "apache parquet access amount analytic analytical analytics apache architectures aws azure based big bigquery cases changes cloud columnar columns common compatibility compression costs data datasets dictionary distributed easy efficient encoding engines environments etl evolution existing expenses fast faster features file files format frameworks google hadoop hive impala improved integration interoperability key lakes large length lower many massive modern multiple necessary new olap operations optimized parallel parallelism parquet parts performance pipelines platforms processing queries query read redshift reduced retrieval rle scalability scale schema services size spark specific splitting storage stored stores support synapse system systems techniques time use warehousing wide workloads",
        "url": "/data/Apache-Parquet.html"
    },
    {
        "id": 78,
        "title": "Apache-Iceberg.html",
        "content": "apache iceberg acid analytics apache changes cloud columns complex data dataset datasets deletes durable dynamic efficiency entire evolution existing features flexible framework frequent hidden historical iceberg key lakes large management manual metadata model models modern need needs object operations partition partitioning partitions petabyte previous queries query reliable scalability scale schema storage supports time transactions travel updates upserts use users versioning versions",
        "url": "/data/Apache-Iceberg.html"
    },
    {
        "id": 79,
        "title": "Graph-Databases-ArgoDB-Neo4j.html",
        "content": "graph databases argodb neo4j acid alice analysis analytics apis arangodb argodb argodbexample b billions breakdown case cases class code complex compliance concept connection consistency create cypher data database databases datasets db deep def detection different distributed document driver edges efficient ensures example excels explanation fast features fraud friend friends function given graph graphdatabase handles high import insights integrates integration key language languages large massive match matching method methods model multi name networks new node nodes password pattern people performance person platforms popular processing python queries query querying rapid recommendation record related relation relationship relationships reliability result scalability scale session sessions setup social specialized storage syntax systems transactions traversal two uri usage use user value way workloads",
        "url": "/data/Graph-Databases-ArgoDB-Neo4j.html"
    },
    {
        "id": 80,
        "title": "GraphQL.html",
        "content": "graphql access accessing accounts acquisition ad administrators ads advertisers amount analytics api apis applications apps audiences authentication automated based benefits budgets business businesses campaigns changes chatbots clients comments communication complex content control conversational creator credentials customer data description developers different direct ecosystem efficiency efficient email end endpoint endpoints engagement environments events exactly facebook features fetching fields flexibility flexible friends front functionality graph graphql group groups id info information insights instagram interactions interfaces key language likes list lists lot managing marketers marketing media members messages messaging messenger metrics microservices multiple name names network notifications one page pages part party performance permissions photos platforms play posts precise predictability primary professional profile profiles programmatic public queries query real redundant relationships replies reports request requests required response rest schema server service sets single specific strongly structure structures subscriptions support teams third time title titles transfer typed types updates usage user users videos way websites whatsapp",
        "url": "/data/GraphQL.html"
    },
    {
        "id": 81,
        "title": "Large-Scale-Data-Ingestion2.html",
        "content": "large scale data ingestion2 acid additional advanced amazon amounts analytics apache application applications automation aws azure based batch beam big capabilities cloud cluster compliance computation confluent connectors data databricks dataflow delta distributed efficient end engineering enterprise event events extension features flink flow framework fully google grade high hubs ingestion iot kafka key kinesis lake large latency logs low managed management manner massive message messaging millions movement multi multiple nifi parallel pipelines platform powerful processing pulsar ready real registry role scalability scale schema security service sources spark storm stream streaming streams system systems telemetry tenancy throughput time tool tools transformation variety versioning wide",
        "url": "/data/Large-Scale-Data-Ingestion2.html"
    },
    {
        "id": 82,
        "title": "Kafka-Producer-Consumer.html",
        "content": "kafka producer consumer apache brokers consumer earliest format import json kafka kafkaconsumer kafkaproducer lambda list message messages offset producer specified topic",
        "url": "/data/Kafka-Producer-Consumer.html"
    },
    {
        "id": 83,
        "title": "sql-statements.html",
        "content": "sql statements add address addresses alias alter alumni autoincrement average avg brown cartesian case check clause column columns combine combines common conditional conditions count create cross cte customers data date default delete department departments departmenttotals desc different distinct doe drop dropping duplicate duplicates e either else email emails employee employees end equality example examples existence existing exists explanation expression filter find first following full group groups hierarchical high id index inner insert integer ip jane join key keywords languages least left limit limits list location main manager managers match matched matching medium michael minimum name names new none null number one order outer output p pagination part partition price prices primary product products programming queries query ranges record records related removes rename result results retrieval retrieve right row rows salary sales second select self set sets side smith snowflake specified speed sql standard statement statements structure student students subquery sum table tables temporary timestamp top total truncate two union unique update value values varchar view virtual",
        "url": "/data/sql-statements.html"
    },
    {
        "id": 84,
        "title": "Apache-Hudi.html",
        "content": "apache hudi acid analytics apache architectures background batch big capabilities changed compaction compression conclusion cost data datasets deletes effective efficient environments features file footprint framework frequent fresh gap guarantees historical hudi incremental incrementals indexes indexing ingestion inserts key lake lakes large latency low management modern near older open overall performance pipelines previous processing queries query querying real scalable scale scenarios sizes source storage support systems techniques time top traditional transaction transactional transactions travel updates upserts users versions",
        "url": "/data/Apache-Hudi.html"
    },
    {
        "id": 85,
        "title": "sql-create-view.html",
        "content": "sql create view conditions create department departments e employee employees group join joins names overview query salaries salary select simple sql statement sum total view",
        "url": "/data/sql-create-view.html"
    },
    {
        "id": 86,
        "title": "Query-Performance.html",
        "content": "query performance access advanced age aggregations amount analysis analyze automatic aws batch benefit best better bigquery bottlenecks caching city clauses cloud clustering clusters column columns complex compute conditions consumption cost costs count customers data database databases dataset datasets date decimal decisions denormalization denormalize desc disk distribution efficiency efficient employees ensure executed execution explain explicit fast faster filtering frequently full group grouped hash help id importance improvement index indexes indexing inefficiencies inserts int join joins key keys large leverage limit maintenance materialized memory merge multiple name names need nodes number offset olap operational optimization optimized optimizer optimizing order partition partitioned partitioning performance plan practices precomputed price products proper queries query range redshift reducing regular regularly resource result results rows run sales scalable scan scans segments select single size smaller snowflake sort space specific sql statistics stores suboptimal subset systems table tables tasks techniques times tools types updates use using utilize view views virtual warehouses",
        "url": "/data/Query-Performance.html"
    },
    {
        "id": 87,
        "title": "sql_overview.html",
        "content": "sql overview ability access additional analysis analytical category changes characteristics columns command commands common commonly complex control cube current data database databases dcl ddl definition delete dml dql drop elements existing extensions functionality functions grant group index indexes insert inserting integrity isolation language level modifies new object objects one oracle point privileges procedural purpose query rank records relational removes retrieval roles rollback rollup rows schemas select server significance specific specifies sql structure structured structures table tables tcl transaction transactions types update used users variants window",
        "url": "/data/sql_overview.html"
    },
    {
        "id": 88,
        "title": "Apache-Kafka.html",
        "content": "apache kafka aggregation analytics apache application architecture availability brokers cases cluster communication compaction confluent connect consumers data decoupled delivery different disk durability easy ecosystem exactly external fault hardware high immutable integration integrations kafka key large latency latest library load log long low messages messaging minimal multiple options partition partitions parts policies processing producers publish range real records regist requirements retention scaling schema semantics sequence servers sinks sources storage stream streams subscribe system systems throughput time tolerance tools topics use value volumes wide",
        "url": "/data/Apache-Kafka.html"
    },
    {
        "id": 89,
        "title": "data-warehouse-architecture.html",
        "content": "data warehouse architecture approach architecture centralized data denormalized design dimensional enterprise flexible inmon integration kimball marts modeling scalable warehouse",
        "url": "/data/data-warehouse-architecture.html"
    }
]